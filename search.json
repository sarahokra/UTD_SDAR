[
  {
    "objectID": "TWBC.html",
    "href": "TWBC.html",
    "title": "Female Breast Cancer in Taiwan 2010-2021",
    "section": "",
    "text": "# Load required packages\npacman::p_load(ggplot2, plotly, scales)\n\n# 設定工作目錄\n#setwd(\"C:/Users/dells/Desktop/quarto/quarto_website/UTD_SDAR\")\n\n# 匯入 CSV 文件\nTWBC &lt;- read.csv(\"TWBC_R.csv\")\n\n# 檢視資料表格\nView(TWBC)\n\n# Create the base plot\nbc &lt;- ggplot(TWBC, aes(N_Incidence, N_Deaths, color = Region)) +\n  geom_point(aes(size = N_Incidence, frame = Year, ids = City))\n\nWarning in geom_point(aes(size = N_Incidence, frame = Year, ids = City)):\nIgnoring unknown aesthetics: frame and ids\n\n# Display the static plot\nbc\n\n\n\n\n\n\n\n# Enhance the plot\nbc &lt;- ggplot(TWBC, aes(N_Incidence, N_Deaths, color = Region)) +\n  geom_point(aes(size = N_Incidence, frame = Year, ids = City, alpha = 0.3)) +\n  scale_x_log10(labels = scales::comma_format()) +\n  labs(title = \"Female Breast Cancer in Taiwan: Nunber of Incidence vs Deaths\",\n       x = \"Nunber of Incidence\", \n       y = \"Nunber of Deaths\",\n       color = \"Region\",\n       size = \"Number of Incidence\") +\n  theme_minimal()\n\nWarning in geom_point(aes(size = N_Incidence, frame = Year, ids = City, :\nIgnoring unknown aesthetics: frame and ids\n\n# Display the enhanced static plot\nbc  \n\n\n\n\n\n\n\n# Create the interactive plot\ninteractive_plot &lt;- ggplotly(bc)\n\n# Display the interactive plot\ninteractive_plot",
    "crumbs": [
      "Home",
      "My Implementation",
      "Female Breast Cancer in Taiwan"
    ]
  },
  {
    "objectID": "TWBC.html#dashboard",
    "href": "TWBC.html#dashboard",
    "title": "Female Breast Cancer in Taiwan 2010-2021",
    "section": "Dashboard",
    "text": "Dashboard\n\n\nFull Screen",
    "crumbs": [
      "Home",
      "My Implementation",
      "Female Breast Cancer in Taiwan"
    ]
  },
  {
    "objectID": "TWBC.html#website-application",
    "href": "TWBC.html#website-application",
    "title": "Female Breast Cancer in Taiwan 2010-2021",
    "section": "Website Application",
    "text": "Website Application\n\n\nFull Screen",
    "crumbs": [
      "Home",
      "My Implementation",
      "Female Breast Cancer in Taiwan"
    ]
  },
  {
    "objectID": "IM_Progress02.html",
    "href": "IM_Progress02.html",
    "title": "Progress Presentation",
    "section": "",
    "text": "Traditional Chinese Medicine for Everyday Wellness",
    "crumbs": [
      "Home",
      "EPPS6354",
      "Progress Presentation"
    ]
  },
  {
    "objectID": "IM_Progress02.html#data-collection-progress-30",
    "href": "IM_Progress02.html#data-collection-progress-30",
    "title": "Progress Presentation",
    "section": "2.1 Data Collection (Progress: 30%)",
    "text": "2.1 Data Collection (Progress: 30%)\n\n2.1.1 Web Scraping TCM Textbooks and Websites Using Python\nExample script:\n\n\nCode\nimport requests\nfrom bs4 import BeautifulSoup\nimport pandas as pd\nimport time\n\nheaders = {\"User-Agent\": \"Mozilla/5.0\"}\nbase_url = \"https://www.zenheart.com.tw/\"\nmeridian_urls = [f\"{base_url}Meridian{str(i).zfill(2)}.php\" for i in range(1, 15)]\n\nall_acupoints = []\n\ndef extract_zhuzhi(html):\n    soup = BeautifulSoup(html, 'html.parser')\n    for p in soup.find_all('p'):\n        if p.get_text(strip=True) == \"主治\":\n            container_div = p.find_parent('div')\n            if container_div:\n                h3 = container_div.find('h3')\n                if h3:\n                    return h3.get_text(strip=True)\n    return None\n\ndef get_acupoint_name(soup):\n    h2 = soup.find(\"h2\", class_=\"h1 u-heading-v7__title\")\n    return h2.get_text(strip=True) if h2 else \"\"\n\nfor meridian_url in meridian_urls:\n    try:\n        res = requests.get(meridian_url, headers=headers)\n        res.encoding = 'utf-8'\n        soup = BeautifulSoup(res.text, 'html.parser')\n\n        links = soup.find_all(\"a\", href=True)\n        acupoint_links = [\n            base_url + link[\"href\"]\n            for link in links if \"Meridian\" in link[\"href\"] and \"_\" in link[\"href\"]\n        ]\n        acupoint_links = list(set(acupoint_links))\n\n        for acupoint_url in acupoint_links:\n            try:\n                r = requests.get(acupoint_url, headers=headers)\n                r.encoding = 'utf-8'\n                acupoint_html = r.text\n                s = BeautifulSoup(acupoint_html, 'html.parser')\n\n                zhuzhi = extract_zhuzhi(acupoint_html)\n                name = get_acupoint_name(s)\n\n                all_acupoints.append({\n                    \"Acupoint Name\": name,\n                    \"URL\": acupoint_url,\n                    \"Indications\": zhuzhi\n                })\n                time.sleep(0.3)\n\n            except Exception as e:\n                continue\n\n    except Exception as e:\n        continue\n\ndf = pd.DataFrame(all_acupoints)\ndf.to_csv(\"zenheart_acupoints.csv\", index=False, encoding='utf-8-sig')\n\n\n\n\n2.1.2 Manual Data Correction\n\nIncludes issues like acupoint codes or characters inconsistent\n\nCurrently performing manual matching and correction\n\n📥 View Dataset",
    "crumbs": [
      "Home",
      "EPPS6354",
      "Progress Presentation"
    ]
  },
  {
    "objectID": "IM_Progress02.html#importing-excel-file-into-postgresql-trial",
    "href": "IM_Progress02.html#importing-excel-file-into-postgresql-trial",
    "title": "Progress Presentation",
    "section": "2.2 Importing Excel File into PostgreSQL (Trial)",
    "text": "2.2 Importing Excel File into PostgreSQL (Trial)\n\nSet up connections: to connect to local SQL database\n\nImported meridian and acupoint data into PostgreSQL\n\nExample script:\n\n\nCode\nlibrary(readxl)\nlibrary(DBI)\nlibrary(RPostgres)\n\nacupoint &lt;- read_excel(\"TCMtest01.xlsx\", sheet = \"Acupoint\")\nmeridian &lt;- read_excel(\"TCMtest01.xlsx\", sheet = \"Meridian\")\n\ncon &lt;- dbConnect(\n  RPostgres::Postgres(),\n  dbname = \"TCMtest01\",\n  host = \"localhost\",\n  port = 5432,\n  user = \"postgres\",\n  password = \"Ting87724$\"\n)\n\ndbExecute(con, \"DROP TABLE IF EXISTS Acupoint;\")\ndbExecute(con, \"DROP TABLE IF EXISTS Meridian;\")\n\ndbExecute(con, \"\n  CREATE TABLE meridian (\n    meridian_code VARCHAR PRIMARY KEY,\n    meridian_eng VARCHAR,\n    meridian_chi VARCHAR\n  );\n\")\n\ndbExecute(con, \"\n  CREATE TABLE acupoint (\n    acupoint_code VARCHAR PRIMARY KEY,\n    acupoint_eng VARCHAR,\n    acupoint_chi VARCHAR,\n    body_acu VARCHAR,\n    indication VARCHAR,\n    function VARCHAR,\n    meridian_code VARCHAR REFERENCES Meridian(meridian_code),\n    location_chi VARCHAR,\n    location_ima VARCHAR\n  );\n\")\n\nmeridian &lt;- meridian[, !names(meridian) %in% \"m_ID\"]\nacupoint &lt;- acupoint[, !names(acupoint) %in% \"a_ID\"]\n\ndbWriteTable(con, \"meridian\", meridian, append = TRUE, row.names = FALSE)\ndbWriteTable(con, \"acupoint\", acupoint, append = TRUE, row.names = FALSE)\ndbDisconnect(con)\n\n\n\n2.2.1 TCMtest01 Database:",
    "crumbs": [
      "Home",
      "EPPS6354",
      "Progress Presentation"
    ]
  },
  {
    "objectID": "IM_Progress02.html#building-an-r-shiny-app-trial",
    "href": "IM_Progress02.html#building-an-r-shiny-app-trial",
    "title": "Progress Presentation",
    "section": "2.3 Building an R Shiny App (Trial)",
    "text": "2.3 Building an R Shiny App (Trial)\nPreliminary interface design:",
    "crumbs": [
      "Home",
      "EPPS6354",
      "Progress Presentation"
    ]
  },
  {
    "objectID": "IM_assignment07.html",
    "href": "IM_assignment07.html",
    "title": "Assignment 7",
    "section": "",
    "text": "I used my password to access my database on my local PostgreSQL server.\n\n\n\nSee bellowed Shinyapp.\n\n\n\nSee bellowed Shinyapp.",
    "crumbs": [
      "Home",
      "EPPS6354",
      "Assignment 7"
    ]
  },
  {
    "objectID": "IM_assignment07.html#a.-be-sure-you-enter-your-password-to-access-your-database-on-your-local-postgresql-server",
    "href": "IM_assignment07.html#a.-be-sure-you-enter-your-password-to-access-your-database-on-your-local-postgresql-server",
    "title": "Assignment 7",
    "section": "",
    "text": "I used my password to access my database on my local PostgreSQL server.",
    "crumbs": [
      "Home",
      "EPPS6354",
      "Assignment 7"
    ]
  },
  {
    "objectID": "IM_assignment07.html#b.-change-the-sorting-of-salary-to-from-high-to-low",
    "href": "IM_assignment07.html#b.-change-the-sorting-of-salary-to-from-high-to-low",
    "title": "Assignment 7",
    "section": "",
    "text": "See bellowed Shinyapp.",
    "crumbs": [
      "Home",
      "EPPS6354",
      "Assignment 7"
    ]
  },
  {
    "objectID": "IM_assignment07.html#c.-try-another-variable-in-another-table",
    "href": "IM_assignment07.html#c.-try-another-variable-in-another-table",
    "title": "Assignment 7",
    "section": "",
    "text": "See bellowed Shinyapp.",
    "crumbs": [
      "Home",
      "EPPS6354",
      "Assignment 7"
    ]
  },
  {
    "objectID": "IM_assignment05.html",
    "href": "IM_assignment05.html",
    "title": "Assignment 5",
    "section": "",
    "text": "Choose 1 or 2 to answer and answer the rest. Prepare your answers in presentation format and be ready to present in class",
    "crumbs": [
      "Home",
      "EPPS6354",
      "Assignment 5"
    ]
  },
  {
    "objectID": "IM_assignment05.html#a-the-graph-is-disconnected.",
    "href": "IM_assignment05.html#a-the-graph-is-disconnected.",
    "title": "Assignment 5",
    "section": "(a) The graph is disconnected.",
    "text": "(a) The graph is disconnected.\nA disconnected graph in an ERD means that some entities (rectangles) are not connected to the rest of the entities. This implies that entities in the database have no relationships with some of the other entities. For example, in an enterprise, some departments work together in a branch but not with the departments in other branches.",
    "crumbs": [
      "Home",
      "EPPS6354",
      "Assignment 5"
    ]
  },
  {
    "objectID": "IM_assignment05.html#b-the-graph-has-a-cycle.",
    "href": "IM_assignment05.html#b-the-graph-has-a-cycle.",
    "title": "Assignment 5",
    "section": "(b) The graph has a cycle.",
    "text": "(b) The graph has a cycle.\nA graph containing a cycle means that in an ERD, starting from a certain entity, following a series of relationships will eventually lead back to the same entity. This implies that no entity is entirely isolated in the database—each entity is related to at least two other entities, and eventually forming a cycle. For example, an Employee belongs to a Department, which may be linked to certain Projects, and these projects may involve the same or other employees, thus forming a cycle.",
    "crumbs": [
      "Home",
      "EPPS6354",
      "Assignment 5"
    ]
  },
  {
    "objectID": "IM_assignment05.html#a-consider-the-employee-database",
    "href": "IM_assignment05.html#a-consider-the-employee-database",
    "title": "Assignment 5",
    "section": "(a) Consider the employee database",
    "text": "(a) Consider the employee database\n\nwhere the primary keys are underlined. Give an expression in SQL for each of the following queries. (Hint: use from employee as e, works as w, company as c, manages as m)\n\ni Find ID and name of each employee who lives in the same city as the location of the company for which the employee works.\nSELECT e.ID, e.person_name\nFROM employee AS e\nJOIN works AS w ON e.ID = w.ID\nJOIN company AS c ON w.company_name = c.company_name\nWHERE e.city = c.city;\n\n\nii Find ID and name of each employee who lives in the same city and on the same street as does her or his manager.\nSELECT e.ID, e.person_name\nFROM employee AS e\nJOIN manages AS m ON e.ID = m.ID\nJOIN employee AS mgr ON m.manager_id = mgr.ID\nWHERE e.city = mgr.city AND e.street = mgr.street;\n\n\niii Find ID and name of each employee who earns more than the average salary of all employees of her or his company.\nSELECT e.ID, e.person_name\nFROM employee AS e\nJOIN works AS w ON e.ID = w.ID\nWHERE w.salary &gt; (\n    SELECT AVG(w2.salary)\n    FROM works AS w2\n    WHERE w2.company_name = w.company_name\n);",
    "crumbs": [
      "Home",
      "EPPS6354",
      "Assignment 5"
    ]
  },
  {
    "objectID": "IM_assignment05.html#b-consider-the-following-sql-query-that-seeks-to-find-a-list-of-titles-of-all-courses-taught-in-spring-2017-along-with-the-name-of-the-instructor.",
    "href": "IM_assignment05.html#b-consider-the-following-sql-query-that-seeks-to-find-a-list-of-titles-of-all-courses-taught-in-spring-2017-along-with-the-name-of-the-instructor.",
    "title": "Assignment 5",
    "section": "(b) Consider the following SQL query that seeks to find a list of titles of all courses taught in Spring 2017 along with the name of the instructor.",
    "text": "(b) Consider the following SQL query that seeks to find a list of titles of all courses taught in Spring 2017 along with the name of the instructor.\n\nWhat is wrong with this query? (Hint: check book website)\n\nfile.exists(\"sql.db\")\n\n[1] TRUE\n\nlibrary(DBI)\nlibrary(RSQLite)\n\n# Establishing a SQLite Connection\nconn &lt;- dbConnect(SQLite(), \"sql.db\")\n\n# Set Quarto to use this SQL connection\nknitr::opts_chunk$set(connection = conn)\n\n\nselect name, title\nfrom instructor natural join teaches natural join section natural join course\nwhere semester = 'Spring' and year = 2017;\n\n\n3 records\n\n\nname\ntitle\n\n\n\n\nBrandt\nGame Design\n\n\nBrandt\nGame Design\n\n\nKim\nIntro. to Digital Systems\n\n\n\n\n\nNatural join is an operation performed on two relations, producing a new relation as a result. Unlike the Cartesian product, which combines every tuple from the first relation with every tuple from the second relation without any condition, natural join selects only those tuples where the values match on the common attributes present in both relations.\nTherefore, in this case, natural join may incorrectly match dept_name in instructor and course table:\nBoth instructor and course tables contain the dept_name attribute. However, dept_name in the instructor table represents the department to which the instructor belongs, whereas in the course table, it represents the department offering the course. Since natural join enforces equality on all common attributes, this leads to the following issue: If the instructor’s department (instructor.dept_name) does not match the department offering the course (ourse.dept_name), the corresponding record will not appear in the result. This incorrectly excludes courses that are cross-listed across departments, leading to incomplete query results.\nTo avoid natural join from treating all matching attributes as join conditions, SQL provides a form of inner join that allows us to specify explicit join conditions, as shown below:\n\nselect name, title\nfrom (instructor join teaches using (ID)) \njoin section using (course_id, sec_id)\njoin course using (course_id)\nwhere section.semester = 'Spring' and section.year = 2017;\n\n\n3 records\n\n\nname\ntitle\n\n\n\n\nBrandt\nGame Design\n\n\nBrandt\nGame Design\n\n\nKim\nIntro. to Digital Systems\n\n\n\n\n\n(The above content refers to P.126-P.131 of the textbook, SKS.)",
    "crumbs": [
      "Home",
      "EPPS6354",
      "Assignment 5"
    ]
  },
  {
    "objectID": "IM_assignment03.html",
    "href": "IM_assignment03.html",
    "title": "Assignment 3",
    "section": "",
    "text": "file.exists(\"sql.db\")\n\n[1] TRUE\n\n\n\nlibrary(DBI)\nlibrary(RSQLite)\n\n# Establishing a SQLite Connection\nconn &lt;- dbConnect(SQLite(), \"sql.db\")\n\n# Set Quarto to use this SQL connection\nknitr::opts_chunk$set(connection = conn)",
    "crumbs": [
      "Home",
      "EPPS6354",
      "Assignment 3"
    ]
  },
  {
    "objectID": "IM_assignment03.html#i.-students-ids-hint-from-the-takes-relation",
    "href": "IM_assignment03.html#i.-students-ids-hint-from-the-takes-relation",
    "title": "Assignment 3",
    "section": "i. Students IDs (hint: from the takes relation)",
    "text": "i. Students IDs (hint: from the takes relation)\n\nSELECT ID FROM takes;\n\n\nDisplaying records 1 - 10\n\n\nID\n\n\n\n\n00128\n\n\n00128\n\n\n12345\n\n\n12345\n\n\n12345\n\n\n12345\n\n\n19991\n\n\n23121\n\n\n44553\n\n\n45678",
    "crumbs": [
      "Home",
      "EPPS6354",
      "Assignment 3"
    ]
  },
  {
    "objectID": "IM_assignment03.html#ii.-instructors",
    "href": "IM_assignment03.html#ii.-instructors",
    "title": "Assignment 3",
    "section": "ii. Instructors",
    "text": "ii. Instructors\n\nselect name from instructor\n\n\nDisplaying records 1 - 10\n\n\nname\n\n\n\n\nSrinivasan\n\n\nWu\n\n\nMozart\n\n\nEinstein\n\n\nEl Said\n\n\nGold\n\n\nKatz\n\n\nCalifieri\n\n\nSingh\n\n\nCrick",
    "crumbs": [
      "Home",
      "EPPS6354",
      "Assignment 3"
    ]
  },
  {
    "objectID": "IM_assignment03.html#iii.-departments",
    "href": "IM_assignment03.html#iii.-departments",
    "title": "Assignment 3",
    "section": "iii. Departments",
    "text": "iii. Departments\n\nselect dept_name from department\n\n\n7 records\n\n\ndept_name\n\n\n\n\nBiology\n\n\nComp. Sci.\n\n\nElec. Eng.\n\n\nFinance\n\n\nHistory\n\n\nMusic\n\n\nPhysics",
    "crumbs": [
      "Home",
      "EPPS6354",
      "Assignment 3"
    ]
  },
  {
    "objectID": "IM_assignment03.html#i.-find-the-id-and-name-of-each-student-who-has-taken-at-least-one-comp.-sci.-course-make-sure-there-are-no-duplicate-names-in-the-result.",
    "href": "IM_assignment03.html#i.-find-the-id-and-name-of-each-student-who-has-taken-at-least-one-comp.-sci.-course-make-sure-there-are-no-duplicate-names-in-the-result.",
    "title": "Assignment 3",
    "section": "i. Find the ID and name of each student who has taken at least one Comp. Sci. course; make sure there are no duplicate names in the result.",
    "text": "i. Find the ID and name of each student who has taken at least one Comp. Sci. course; make sure there are no duplicate names in the result.\n\nSELECT DISTINCT S.ID, S.name\nFROM student S\nJOIN takes T ON S.ID = T.ID\nJOIN course C ON T.course_id = C.course_id\nWHERE C.dept_name = 'Comp. Sci.';\n\n\n6 records\n\n\nID\nname\n\n\n\n\n00128\nZhang\n\n\n12345\nShankar\n\n\n45678\nLevy\n\n\n54321\nWilliams\n\n\n76543\nBrown\n\n\n98765\nBourikas",
    "crumbs": [
      "Home",
      "EPPS6354",
      "Assignment 3"
    ]
  },
  {
    "objectID": "IM_assignment03.html#ii.-add-grades-to-the-list.",
    "href": "IM_assignment03.html#ii.-add-grades-to-the-list.",
    "title": "Assignment 3",
    "section": "ii. Add grades to the list.",
    "text": "ii. Add grades to the list.\n\nSELECT DISTINCT S.ID, S.name, T.grade\nFROM student S\nJOIN takes T ON S.ID = T.ID\nJOIN course C ON T.course_id = C.course_id\nWHERE C.dept_name = 'Comp. Sci.';\n\n\nDisplaying records 1 - 10\n\n\nID\nname\ngrade\n\n\n\n\n00128\nZhang\nA\n\n\n00128\nZhang\nA-\n\n\n12345\nShankar\nC\n\n\n12345\nShankar\nA\n\n\n45678\nLevy\nF\n\n\n45678\nLevy\nB+\n\n\n45678\nLevy\nB\n\n\n54321\nWilliams\nA-\n\n\n54321\nWilliams\nB+\n\n\n76543\nBrown\nA",
    "crumbs": [
      "Home",
      "EPPS6354",
      "Assignment 3"
    ]
  },
  {
    "objectID": "IM_assignment03.html#iii.-find-the-id-and-name-of-each-student-who-has-not-taken-any-course-offered-before-2017.",
    "href": "IM_assignment03.html#iii.-find-the-id-and-name-of-each-student-who-has-not-taken-any-course-offered-before-2017.",
    "title": "Assignment 3",
    "section": "iii. Find the ID and name of each student who has not taken any course offered before 2017.",
    "text": "iii. Find the ID and name of each student who has not taken any course offered before 2017.\n\nSELECT S.ID, S.name\nFROM student S\nWHERE NOT EXISTS (\n    SELECT 1\n    FROM takes T\n    WHERE T.ID = S.ID\n    AND T.year &lt; 2017\n);\n\n\nDisplaying records 1 - 10\n\n\nID\nname\n\n\n\n\n00128\nZhang\n\n\n12345\nShankar\n\n\n19991\nBrandt\n\n\n23121\nChavez\n\n\n44553\nPeltier\n\n\n45678\nLevy\n\n\n54321\nWilliams\n\n\n55739\nSanchez\n\n\n70557\nSnow\n\n\n76543\nBrown",
    "crumbs": [
      "Home",
      "EPPS6354",
      "Assignment 3"
    ]
  },
  {
    "objectID": "IM_assignment03.html#iv.-for-each-department-find-the-maximum-salary-of-instructors-in-that-department.-you-may-assume-that-every-department-has-at-least-one-instructor.",
    "href": "IM_assignment03.html#iv.-for-each-department-find-the-maximum-salary-of-instructors-in-that-department.-you-may-assume-that-every-department-has-at-least-one-instructor.",
    "title": "Assignment 3",
    "section": "iv. For each department, find the maximum salary of instructors in that department. You may assume that every department has at least one instructor.",
    "text": "iv. For each department, find the maximum salary of instructors in that department. You may assume that every department has at least one instructor.\n\nSELECT dept_name, MAX(salary) AS max_salary\nFROM instructor\nGROUP BY dept_name;\n\n\n7 records\n\n\ndept_name\nmax_salary\n\n\n\n\nBiology\n72000\n\n\nComp. Sci.\n92000\n\n\nElec. Eng.\n80000\n\n\nFinance\n90000\n\n\nHistory\n62000\n\n\nMusic\n40000\n\n\nPhysics\n95000",
    "crumbs": [
      "Home",
      "EPPS6354",
      "Assignment 3"
    ]
  },
  {
    "objectID": "IM_assignment03.html#v.-find-the-lowest-across-all-departments-of-the-per-department-maximum-salary-computed-by-the-preceding-query.",
    "href": "IM_assignment03.html#v.-find-the-lowest-across-all-departments-of-the-per-department-maximum-salary-computed-by-the-preceding-query.",
    "title": "Assignment 3",
    "section": "v. Find the lowest, across all departments, of the per-department maximum salary computed by the preceding query.",
    "text": "v. Find the lowest, across all departments, of the per-department maximum salary computed by the preceding query.\n\nSELECT MIN(max_salary) AS lowest_max_salary\nFROM (\n    SELECT dept_name, MAX(salary) AS max_salary\n    FROM instructor\n    GROUP BY dept_name\n) AS department_max_salaries;\n\n\n1 records\n\n\nlowest_max_salary\n\n\n\n\n40000",
    "crumbs": [
      "Home",
      "EPPS6354",
      "Assignment 3"
    ]
  },
  {
    "objectID": "IM_assignment03.html#vi.-add-names-to-the-list",
    "href": "IM_assignment03.html#vi.-add-names-to-the-list",
    "title": "Assignment 3",
    "section": "vi. Add names to the list",
    "text": "vi. Add names to the list\n\nSELECT I.name, D.lowest_max_salary\nFROM instructor I\nJOIN (\n    SELECT dept_name, MIN(max_salary) AS lowest_max_salary\n    FROM (\n        SELECT dept_name, MAX(salary) AS max_salary\n        FROM instructor\n        GROUP BY dept_name\n    ) AS department_max_salaries\n) AS D ON I.dept_name = D.dept_name AND I.salary = D.lowest_max_salary;\n\n\n1 records\n\n\nname\nlowest_max_salary\n\n\n\n\nMozart\n40000",
    "crumbs": [
      "Home",
      "EPPS6354",
      "Assignment 3"
    ]
  },
  {
    "objectID": "IM_assignment01.html",
    "href": "IM_assignment01.html",
    "title": "Assignment 1",
    "section": "",
    "text": "Answer 1, 2, 6 and one of the remaining questions. Prepare your answers in presentation format (e.g. post on website). Members will be selected to present answers in class. Be ready for your presentation.\n\n1. Name and describe three applications you have used that employed a database system to store and access persistent data. (e.g. airlines, online trade, banking, university system)\n\n\n\n\n\n\n\n\nApplications\nPurpose\nFeatures\n\n\n\n\nOnline Shopping Platform (e.g., Amazon)\nStores user account information, product details, order history, logistics data, and user behavior.\nSupports concurrent access for multiple users and maintains query efficiency.\n\n\nBanking System (e.g., Bank of America Mobile App)\nManages account balances, transaction histories, loans, and other financial product information.\nEnsures data consistency and security while preventing data loss and errors.\n\n\nUniversity Course Management System (e.g., UTD Course Registration System)\nStores course information (e.g., course ID, credit hours, schedule, instructor, etc.), tracks registered students, calculates total earned credits, and determines tuition fees.\nSupports concurrent access for multiple users and enables real-time information updates.\n\n\n\n\n\n2. Propose three applications in domain projects (e.g. criminology, economics, brain science, etc.) Be sure you include:\n\nPurpose\nFunctions\nSimple interface design\n\n\n\n\n\n\n\n\n\n\nDomain\nPurpose\nFunctions\nInterface Design\n\n\n\n\nHealthcare\nControl of acute infectious diseases – Supply users with immediate prevention information during pandemics.\n\nDisplay current policies, infection, and death counts.\nBrowse locations visited by infected individuals.\nProvide testing reservations.\n\n\nEssential info display area for policies and counts.\nSearch bar and infection map.\nTesting facility search field.\n\n\n\nEducation\nLearning portfolio management – Enable students to store learning data, assess their chances of admission, and support them in the university application process reviews.\n\nDisplay and edit student information.\nRecord and query course history.\nAnalyze student performance and estimate admission chances.\n(Students) Upload documents (e.g., transcripts, awards). / (Teachers) Verify the authenticity of student submissions.\nPackage and automatically send data to schools.\n\n\nStudent info display area.\nCourse record display area and search field.\nPerformance radar chart and school. recommendations list.\nUpload fields for transcripts, awards, and reflections / Verification fields for student documents.\nData packaging and send button.\n\n\n\nTourism\nTravel planning – Store information about tourist attractions and suggest destinations, itineraries, or activities based on visitors’ interests and needs.\n\nCollect tourist preferences (e.g., nature, culture).\nGenerate recommendations based on weather, traffic, and feedback.\nProvide maps and route planning.\nCollect tourist feedback to improve services.\n\n\nPreference selection interface.\nRecommended itinerary and attractions list.\nRoute planning map.\nFeedback input field.\n\n\n\n\n\n\n3. If data can be retrieved efficiently and effectively, why data mining is needed?\nData retrieval focuses on efficiently locating data already stored in a database. In contrast, data mining applies statistical methods and artificial intelligence to extract valuable insights from existing data. This process assists businesses and researchers with decision-making, forecasting future trends, and even uncovering new knowledge. For example, in healthcare, medical data mining helps identify disease risk factors, categorize patient groups, and determine effective treatment strategies, ultimately enhancing the quality and efficiency of healthcare services. In social media, analyzing user behavior and sentiment on platforms aids businesses in understanding market trends, product reputation, and customer satisfaction, facilitating the development of effective marketing strategies.\n\n\n4. Why NoSQL systems emerged in the 2000s? Briefly contrast their features with traditional database systems.\nAfter the 2000s, the demand for emerging applications like social media and big data analytics shifted data storage requirements. Data types expanded beyond traditional structured formats to include semi-structured and unstructured formats like JSON and XML. These changes necessitated large-scale storage and rapid scalability. To accommodate high-concurrency read and write operations, NoSQL systems became suitable alternatives to traditional relational database management systems (RDBMS), which rely on row-oriented storage and strict consistency. NoSQL databases offer better flexibility for diverse data types, making them useful for large-scale social media data and real-time queries.\nKey Characteristics of NoSQL Systems:\n1. Flexible Data Model: NoSQL databases lack a fixed schema, storing semi-structured or unstructured data (e.g., JSON, XML).\n2. High Scalability: Their distributed architecture supports cost-effective horizontal scaling compared to traditional vertical scaling.\n3. Eventual Consistency: NoSQL allows temporary data inconsistencies, enhancing availability through eventual consistency.\n4. Flexible Query Mechanisms: Many NoSQL databases offer custom APIs or alternative query languages instead of SQL.\n5. Optimized for Big Data: NoSQL systems excel in handling large data volumes, such as big data storage and log analysis.\nNoSQL Systems vs. Traditional RDBMS:\n\n\n\n\n\n\n\n\nFeature\nNoSQL Systems\nRelational Databases (RDBMS)\n\n\n\n\nData Model\nSemi-structured or unstructured data: document-based, key-value, and graph-based models.\nStructured data stored in tables (rows and columns) with a strict schema.\n\n\nQuery Language\nCustom APIs or NoSQL query languages.\nSQL (Structured Query Language).\n\n\nScalability\nHorizontal scaling (Scale-out) fits distributed architectures.\nVertical scaling (Scale-up) depends on enhancing single-node performance.\n\n\nConsistency\nEventual consistency favors availability and scalability.\nStrong consistency (ACID) guarantees strict data integrity.\n\n\nUse Cases\nSocial media, big data applications, distributed systems.\nFinancial transactions, enterprise applications, and traditional business systems.\n\n\nPerformance Advantages\nOptimized for high-volume read and write operations.\nOptimized for structured queries and transactional processing.\n\n\n\n\n\n5. What are the things current database system cannot do?\n1. Automated Semantic Understanding: Databases cannot grasp the semantics of data and can only operate according to established rules.\n2. Automated Decision-Making Suggestions: Database systems do not possess advanced analytical abilities and depend on external applications for data analysis.\n\n\n6. Describe at least three tables that might be used to store information in a social-network/social media system such as Twitter or Reddit.\n\n\n\n\n\n\n\n\nTable\nFields\nPurpose\n\n\n\n\nUsers\nUserID, Username, Account, Citizenship, UserLevel, ProfilePicture, Membership, AverageLogintime.\nStores basic user information and authentication data.\n\n\nPosts\nPostID, UserID, Content, ContentEmotion, Tag, Language, Location, Timestamp, LikesCount, CommentsCount, AverageViewingTime.\nStores the content of each post along with its interaction data.\n\n\nInteractions\nInteractionID, UserID, PostID, InteractionType (e.g., Like, Comment, Share), InteractionContent, Timestamp.\nStores the interactions link with each post.",
    "crumbs": [
      "Home",
      "EPPS6354",
      "Assignment 1"
    ]
  },
  {
    "objectID": "DV_assignment07.html",
    "href": "DV_assignment07.html",
    "title": "Assignment 7",
    "section": "",
    "text": "knitr::opts_chunk$set(warning = FALSE)",
    "crumbs": [
      "Home",
      "EPPS6356",
      "Assignment 7"
    ]
  },
  {
    "objectID": "DV_assignment07.html#scatterplot-in-shiny",
    "href": "DV_assignment07.html#scatterplot-in-shiny",
    "title": "Assignment 7",
    "section": "Scatterplot in Shiny",
    "text": "Scatterplot in Shiny\n\n\nScatterplot Visualization: The scatterplot plots data points for each Texas county, where: The x-axis typically represents the voter registration numbers. The y-axis represents voter turnout, allowing users to observe trends and outliers in turnout relative to registration across counties.\nInteractive Election Type Filters: The app includes interactive controls (such as buttons or checkboxes) for filtering the displayed data by election type. This feature enables users to toggle between election types (e.g., presidential, midterm, primary) and focus only on federal elections conducted in Texas from 2016 onward. By selecting or deselecting election types, users can observe differences in turnout and registration for each election context.\nDynamic Plot Updates: When the user adjusts the filters, the scatterplot updates dynamically, enabling a comparison of turnout versus registration across different election types and timeframes. This feature provides a deeper look into how different federal elections might impact voter behavior at the county level.\nThe interactive nature of the scatterplot, combined with election-type filters, allows for a user-friendly exploration of turnout and registration patterns over time across Texas counties.",
    "crumbs": [
      "Home",
      "EPPS6356",
      "Assignment 7"
    ]
  },
  {
    "objectID": "DV_assignment07.html#bubble-chart-in-shiny",
    "href": "DV_assignment07.html#bubble-chart-in-shiny",
    "title": "Assignment 7",
    "section": "Bubble Chart in Shiny",
    "text": "Bubble Chart in Shiny\n\n\nThe Shiny app features an interactive bubble chart that compares voter registration against voter turnout across Texas counties. In this visualization:\n\nX-Axis: Represents the voter registration rate for each county.\nY-Axis: Represents the voter turnout rate, allowing for a quick comparison of how many registered voters actually turned out in each county.\nBubble Size: Reflects the percentage of the Black population in each county. Larger bubbles indicate a higher proportion of Black residents within that county.\nUser Controls: Users can select specific Texas counties and adjust parameters to display rates of registered voters, turnout, and Black population percentage.\n\nThis design allows users to investigate trends by demographic and region, revealing patterns in voter registration and turnout in relation to the Black population distribution across Texas counties. The adjustable inputs provide a tailored look at each county’s data, enabling insights into which counties may benefit from targeted voter engagement strategies.",
    "crumbs": [
      "Home",
      "EPPS6356",
      "Assignment 7"
    ]
  },
  {
    "objectID": "DV_assignment05.html",
    "href": "DV_assignment05.html",
    "title": "Assignment 5",
    "section": "",
    "text": "1. Using sample datasets or own data, create the following charts using only R graphics\nfunctions (i.e. without using any other packages). Be sure you customize the chart with your own style/theme (e.g. font, color, pch, etc.)\n\n# 設定工作目錄\n#setwd(\"C:/Users/dells/Desktop/quarto/quarto_website/UTD_SDAR\")\n\n# 匯入 CSV 文件\nTWBC2021 &lt;- read.csv(\"TWBC2021.csv\")\n\n# 檢視資料表格\nView(TWBC2021)\n\na. Histogram\n\n# Histogram\npar(col=\"gray50\", fg=\"gray30\", col.axis=\"gray50\")\nhist(TWBC2021$A_Age, breaks = 10, \n     col = \"gray80\", freq = FALSE, \n     main = \"Histogram of Averge Incidence Age of\\n Female Breast Cancer with Normal Distribution\", \n     xlab = \"Averge Incidence Age\", \n     cex.lab = 1.2) \nmean_hpi &lt;- mean(TWBC2021$A_Age, na.rm = TRUE)\nsd_hpi &lt;- sd(TWBC2021$A_Age, na.rm = TRUE)\nx &lt;- seq(min(TWBC2021$A_Age, na.rm = TRUE), max(TWBC2021$A_Age, na.rm = TRUE), length = 100)\ndn &lt;- dnorm(x, mean = mean_hpi, sd = sd_hpi)\nlines(x, dn, col = \"red\", lwd = 2)\n\n\n\n\n\n\n\npar(mar=c(5.1, 4.1, 4.1, 2.1), col=\"black\", fg=\"black\", col.axis=\"black\")\n\nb. Barchart\ni. Vertical\n\n# Barchart(Vertical)\nsorted_data &lt;- TWBC2021[order(TWBC2021$N_Incidence), ]\n\npar(mar=c(6, 5.5, 3, 2))\nbarplot(\n  sorted_data$N_Incidence, \n  names.arg = sorted_data$City, \n  las = 2,              # X軸標籤旋轉\n  col = \"lightblue\",     # 條形顏色\n  main = \"Number of Incidence by City/County\",\n  ylab = \"Number of Incidence\",\n  ylim = c(0, 3000),\n  cex.names = 0.6,\n  cex.lab = 0.8,         # 調整Y軸標籤（ylab）的字體大小\n  cex.axis = 0.7\n)\n\n\n\n\n\n\n\npar(mar=c(5.1, 4.1, 4.1, 2.1), col=\"black\", fg=\"black\", col.axis=\"black\")\n\nii. Horizonal\n\n# Barchart(Horizonal)\npar(mar=c(4.5, 6, 3, 2.1)) \nbarplot(\n  sorted_data$N_Incidence, \n  names.arg = sorted_data$City, \n  las = 1,              # X軸標籤旋轉\n  col = \"lightblue\",     # 條形顏色\n  main = \"Number of Incidence by City/County\",\n  xlab = \"Number of Incidence\",  # X軸標籤改為表示 N_Incidence\n  horiz = TRUE,          # 設置條形圖為橫向\n  cex.names = 0.55,\n  cex.lab = 0.8,         # 調整X軸標籤（xlab）的字體大小\n  cex.axis = 0.7,\n  xlim = c(0, 3000)      # 設置X軸範圍\n)\n\n\n\n\n\n\n\npar(mar=c(5.1, 4.1, 4.1, 2.1), col=\"black\", fg=\"black\", col.axis=\"black\")\n\nc. Piechart\n\n# Piechart\npar(mar=c(1, 1.5, 3, 1.5), lwd=1)\nregion_counts &lt;- table(TWBC2021$Region)\ncolors &lt;- c(\"darkorchid2\", \"limegreen\", \"firebrick2\", \"darkorange2\", \"royalblue\")\npie(region_counts, \n    labels = paste(names(region_counts)), \n    main = \"Distribution of Regions in the Dataset\", \n    col = colors)\n\n\n\n\n\n\n\npar(mar=c(5.1, 4.1, 4.1, 2.1), col=\"black\", fg=\"black\", col.axis=\"black\")\n\nd. Boxplot\n\n# Boxplot\npar(mar=c(4.5, 6, 3, 2.1),las = 1) \nboxplot(\n  A_Age ~ Region,         # Y軸是N_Incidence，X軸是Divisions\n  data = TWBC2021,                     # 數據來源\n  main = \"Boxplot of N_Incidence by Divisions\",  # 圖表標題\n  xlab = \"Region\",              # X軸標籤\n  ylab = \"Averge Incidence Age\" ,            # Y軸標籤\n  cex.axis = 0.6\n)\n\n\n\n\n\n\n\npar(mar=c(5.1, 4.1, 4.1, 2.1), col=\"black\", fg=\"black\", col.axis=\"black\")\n\ne. Scatterplot\n\n# Scatterplot\npar(las=1, mar=c(6, 6, 4, 4), cex= .7) \nplot.new()\nplot.window(range(TWBC2021$N_Incidence, na.rm = TRUE), range(TWBC2021$N_Deaths, na.rm = TRUE))\nTWBC2021 &lt;- TWBC2021[order(TWBC2021$N_Incidence), ]\nlines(TWBC2021$N_Incidence, TWBC2021$N_Deaths, col=\"gray50\")\npoints(TWBC2021$N_Incidence, TWBC2021$N_Deaths, pch=21, bg=\"white\", cex=1) \npar(col=\"gray50\", fg=\"gray50\", col.axis=\"gray50\")\nbox(bty=\"o\")\naxis(1, at = NULL, labels = TRUE) \naxis(2, at = seq(0, 500, 100))\naxis(4, at = seq(0, 500, 100))\nmtext(\"Number of Incidence\", side=1, line=3, outer=FALSE, col=\"black\", cex=0.8)\nmtext(\"Number of Deaths\", side=2, line=3, las=0, outer=FALSE, col=\"black\", cex=0.8)\ntext(750, 400, \"Number of Incidence\\n vs Deaths\")\ntitle(main = \"Number of Incidence versus Number of Deaths\")\n\n\n\n\n\n\n\npar(mar=c(5.1, 4.1, 4.1, 2.1), col=\"black\", fg=\"black\", col.axis=\"black\")\n\n\n\n2. Repeat 1 using ggplot2, with your own style.\n\n# 設置 CRAN 鏡像\noptions(repos = c(CRAN = \"https://cran.rstudio.com/\"))\n\n# 安裝 ggplot2（若尚未安裝）\nif (!requireNamespace(\"ggplot2\", quietly = TRUE)) {\n  install.packages(\"ggplot2\")\n}\n\n# 載入 ggplot2 套件\nlibrary(ggplot2)\n\n# 安裝 dplyr（若尚未安裝）\nif (!requireNamespace(\"dplyr\", quietly = TRUE)) {\n  install.packages(\"dplyr\")\n}\n\n\n# 載入 dplyr 套件\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\n# 1. Histogram\nggplot(TWBC2021, aes(x = A_Age)) +\n  geom_histogram(aes(y = ..density..), bins = 10, fill = \"gray80\", color = \"gray50\") +\n  stat_function(fun = dnorm, args = list(mean = mean(TWBC2021$A_Age, na.rm = TRUE), \n                                         sd = sd(TWBC2021$A_Age, na.rm = TRUE)), \n                color = \"red\", size = 1) +\n  labs(title = \"Histogram of Average Incidence Age of Female Breast Cancer\\nwith Normal Distribution\",\n       x = \"Average Incidence Age\", y = \"Density\") +\n  theme_minimal() + \n  theme(plot.title = element_text(hjust = 0.5))\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\nWarning: The dot-dot notation (`..density..`) was deprecated in ggplot2 3.4.0.\nℹ Please use `after_stat(density)` instead.\n\n\n\n\n\n\n\n\n# 2. Barchart (Vertical)\nsorted_data &lt;- TWBC2021 %&gt;% arrange(N_Incidence)\nsorted_data &lt;- TWBC2021 %&gt;% arrange(N_Incidence)\nggplot(sorted_data, aes(x = reorder(City, N_Incidence), y = N_Incidence)) +\n  geom_bar(stat = \"identity\", fill = \"lightblue\") +\n  labs(title = \"Number of Incidence by City/County\", x = \"City\", y = \"Number of Incidence\") +\n  theme(\n    axis.text.x = element_text(angle = 90, hjust = 1, size = 8),\n    panel.background = element_rect(fill = \"transparent\", color = NA),  # 讓繪圖區背景透明\n    plot.background = element_rect(fill = \"transparent\", color = NA),   # 讓整體背景透明\n    panel.grid.major = element_line(color = \"gray90\"),   # 保留主要格線\n    panel.grid.minor = element_line(color = \"gray90\"),   # 保留次要格線\n    plot.title = element_text(hjust = 0.5)  # 將標題置中\n  )\n\n\n\n\n\n\n\n# 3. Barchart (Horizontal)\nggplot(sorted_data, aes(x = reorder(City, N_Incidence), y = N_Incidence)) +\n  geom_bar(stat = \"identity\", fill = \"lightblue\") +\n  labs(title = \"Number of Incidence by City/County\", y = \"City\", x = \"Number of Incidence\") +\n  coord_flip() +\n  theme_minimal() + \n  theme(plot.title = element_text(hjust = 0.5))\n\n\n\n\n\n\n\n# 4. Piechart\nregion_counts &lt;- TWBC2021 %&gt;%\n  count(Region)\nggplot(region_counts, aes(x = \"\", y = n, fill = Region)) +\n  geom_bar(stat = \"identity\", width = 1) +\n  coord_polar(theta = \"y\") +\n  labs(title = \"Distribution of Regions in the Dataset\", x = NULL, y = NULL) +\n  theme_void() +\n  scale_fill_manual(values = c(\"darkorchid2\", \"limegreen\", \"firebrick2\", \"darkorange2\", \"royalblue\")) + \n  theme(plot.title = element_text(hjust = 0.5))\n\n\n\n\n\n\n\n# 5. Boxplot\nggplot(TWBC2021, aes(x = Region, y = A_Age)) +\n  geom_boxplot(fill = \"gray\") +  # 將盒子的顏色設為灰色\n  labs(title = \"Boxplot of Average Incidence Age by Region\", x = \"Region\", y = \"Average Incidence Age\") +\n  theme_minimal() + \n  theme(plot.title = element_text(hjust = 0.5))\n\n\n\n\n\n\n\n# 6. Scatterplot\nggplot(TWBC2021, aes(x = N_Incidence, y = N_Deaths)) +\n  geom_point(shape = 21, fill = \"white\", size = 3) +\n  geom_line(color = \"gray50\") +\n  labs(title = \"Number of Incidence vs Number of Deaths\", x = \"Number of Incidence\", y = \"Number of Deaths\") +\n  theme_minimal() +\n  theme(plot.title = element_text(hjust = 0.5)) +  # 將標題置中\n  annotate(\"text\", x = 750, y = 400, label = \"Number of Incidence\\n vs Deaths\")\n\n\n\n\n\n\n\n\n\n\n3. Export the charts using different formats such as:\n\n.pdf\n\n\n\n\n\n\n.jpg\n\n.svg\n\n.tiff\n\n.bmp\n\n\nNote the differences in these file format:\nOn the Quarto website, PDF and SVG files have higher image quality, while JPEG and BMP files have lower image quality, and TIFF files cannot be displayed.",
    "crumbs": [
      "Home",
      "EPPS6356",
      "Assignment 5"
    ]
  },
  {
    "objectID": "DV_assignment03.html",
    "href": "DV_assignment03.html",
    "title": "Assignment 3",
    "section": "",
    "text": "1. Rerun murrell01.R\n\nChoose one of the six charts and explain how it is configured by adding documentation to the codes.\n\n\n# Scatterplot\n\nx &lt;- c(0.5, 2, 4, 8, 12, 16) # Define the x values\ny1 &lt;- c(1, 1.3, 1.9, 3.4, 3.9, 4.8) # Define the y1 values\ny2 &lt;- c(4, .8, .5, .45, .4, .3) # Define the y2 values\n\npar(las=1, mar=c(4, 4, 2, 4), cex=.7) # las=1: Make axis labels always horizontal\n# mar=c(4, 4, 2, 4): Set margins (bottom, left, top, right)\n# cex=0.7: Set the text size to 70% of the default size\n\nplot.new() # Create a new blank plot\nplot.window(range(x), c(0, 6)) # Set up the plotting window with defined x and y ranges\n# range(x): Set the range of x-axis based on x values\n# c(0, 6): Set the y-axis range from 0 to 6\n\nlines(x, y1) # Draw a line connecting the points defined by x and y1 values\nlines(x, y2) # Draw a line connecting the points defined by x and y2 values\n\npoints(x, y1, pch=16, cex=2) # Plot points for the first set of data (x, y1) using solid circles (pch=16)\n# cex=2: Set the point size to twice the default size\npoints(x, y2, pch=21, bg=\"white\", cex=2) # Plot points for the second set of data (x, y2) using open circles with a white fill (pch=21, bg=\"white\")\n# cex=2: Set the point size to twice the default size\n\npar(col=\"gray50\", fg=\"gray50\", col.axis=\"gray50\") # Set the color for lines, text, and axes to gray50\n\naxis(1, at=seq(0, 16, 4)) # Draw the x-axis with ticks at positions 0, 4, 8, 12, and 16\n# The first number in the sequence (0) stands for the starting point of the axis ticks\naxis(2, at=seq(0, 6, 2)) # Draw the left y-axis with ticks at positions 0, 2, 4, and 6\naxis(4, at=seq(0, 6, 2)) # Draw the right y-axis with ticks at positions 0, 2, 4, and 6\n\nbox(bty=\"u\") # Draw a box around the plot with only the top and bottom borders\n\nmtext(\"Travel Time (s)\", side=1, line=2, cex=0.8) # Add x-axis label: \"Travel Time (s)\" at the bottom (side=1)\n# line=2: Position the label two lines away from the axis\n# cex=0.8: Set the text size to 80% of the default\nmtext(\"Responses per Travel\", side=2, line=2, las=0, cex=0.8) # Add left y-axis label: \"Responses per Travel\" (side=2)\n# line=2: Position the label two lines away from the axis\n# las=0: Make the text parallel to the axis\n# cex=0.8: Set the text size to 80% of the default\nmtext(\"Responses per Second\", side=4, line=2, las=0, cex=0.8) # Add right y-axis label: \"Responses per Second\" (side=4)\n# line=2: Position the label two lines away from the axis\n# las=0: Make the text parallel to the axis\n# cex=0.8: Set the text size to 80% of the default\n\ntext(4, 5, \"Bird 131\") # Add text label \"Bird 131\" at coordinates (x=4, y=5)\n\n\n\n\n\n\n\npar(mar=c(5.1, 4.1, 4.1, 2.1), col=\"black\", fg=\"black\", col.axis=\"black\") # Restore the default graphical parameters\n# mar=c(5.1, 4.1, 4.1, 2.1): Set margins back to default values\n# col=\"black\", fg=\"black\", col.axis=\"black\": Reset colors to black\n\n\n\n2. Rerun anscombe01.R (in Teams folder)\n\nCompare the regression models\nCompare different ways to create the plots (e.g. changing colors, line types, plot characters)\n\n\ndata(anscombe)\nsummary(anscombe)\n\n       x1             x2             x3             x4           y1        \n Min.   : 4.0   Min.   : 4.0   Min.   : 4.0   Min.   : 8   Min.   : 4.260  \n 1st Qu.: 6.5   1st Qu.: 6.5   1st Qu.: 6.5   1st Qu.: 8   1st Qu.: 6.315  \n Median : 9.0   Median : 9.0   Median : 9.0   Median : 8   Median : 7.580  \n Mean   : 9.0   Mean   : 9.0   Mean   : 9.0   Mean   : 9   Mean   : 7.501  \n 3rd Qu.:11.5   3rd Qu.:11.5   3rd Qu.:11.5   3rd Qu.: 8   3rd Qu.: 8.570  \n Max.   :14.0   Max.   :14.0   Max.   :14.0   Max.   :19   Max.   :10.840  \n       y2              y3              y4        \n Min.   :3.100   Min.   : 5.39   Min.   : 5.250  \n 1st Qu.:6.695   1st Qu.: 6.25   1st Qu.: 6.170  \n Median :8.140   Median : 7.11   Median : 7.040  \n Mean   :7.501   Mean   : 7.50   Mean   : 7.501  \n 3rd Qu.:8.950   3rd Qu.: 7.98   3rd Qu.: 8.190  \n Max.   :9.260   Max.   :12.74   Max.   :12.500  \n\nlm1 &lt;- lm(y1 ~ x1, data=anscombe)\nsummary(lm1)\n\n\nCall:\nlm(formula = y1 ~ x1, data = anscombe)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1.92127 -0.45577 -0.04136  0.70941  1.83882 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)   \n(Intercept)   3.0001     1.1247   2.667  0.02573 * \nx1            0.5001     0.1179   4.241  0.00217 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.237 on 9 degrees of freedom\nMultiple R-squared:  0.6665,    Adjusted R-squared:  0.6295 \nF-statistic: 17.99 on 1 and 9 DF,  p-value: 0.00217\n\nlm2 &lt;- lm(y2 ~ x2, data=anscombe)\nsummary(lm2)\n\n\nCall:\nlm(formula = y2 ~ x2, data = anscombe)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-1.9009 -0.7609  0.1291  0.9491  1.2691 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)   \n(Intercept)    3.001      1.125   2.667  0.02576 * \nx2             0.500      0.118   4.239  0.00218 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.237 on 9 degrees of freedom\nMultiple R-squared:  0.6662,    Adjusted R-squared:  0.6292 \nF-statistic: 17.97 on 1 and 9 DF,  p-value: 0.002179\n\nlm3 &lt;- lm(y3 ~ x3, data=anscombe)\nsummary(lm3)\n\n\nCall:\nlm(formula = y3 ~ x3, data = anscombe)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-1.1586 -0.6146 -0.2303  0.1540  3.2411 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)   \n(Intercept)   3.0025     1.1245   2.670  0.02562 * \nx3            0.4997     0.1179   4.239  0.00218 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.236 on 9 degrees of freedom\nMultiple R-squared:  0.6663,    Adjusted R-squared:  0.6292 \nF-statistic: 17.97 on 1 and 9 DF,  p-value: 0.002176\n\nlm4 &lt;- lm(y4 ~ x4, data=anscombe)\nsummary(lm4)\n\n\nCall:\nlm(formula = y4 ~ x4, data = anscombe)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-1.751 -0.831  0.000  0.809  1.839 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)   \n(Intercept)   3.0017     1.1239   2.671  0.02559 * \nx4            0.4999     0.1178   4.243  0.00216 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.236 on 9 degrees of freedom\nMultiple R-squared:  0.6667,    Adjusted R-squared:  0.6297 \nF-statistic:    18 on 1 and 9 DF,  p-value: 0.002165\n\nff &lt;- y ~ x\nmods &lt;- setNames(as.list(1:4), paste0(\"lm\", 1:4))\nfor(i in 1:4) {\n  ff[2:3] &lt;- lapply(paste0(c(\"y\",\"x\"), i), as.name)\n  mods[[i]] &lt;- lmi &lt;- lm(ff, data = anscombe)\n  print(anova(lmi))\n}\n\nAnalysis of Variance Table\n\nResponse: y1\n          Df Sum Sq Mean Sq F value  Pr(&gt;F)   \nx1         1 27.510 27.5100   17.99 0.00217 **\nResiduals  9 13.763  1.5292                   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nAnalysis of Variance Table\n\nResponse: y2\n          Df Sum Sq Mean Sq F value   Pr(&gt;F)   \nx2         1 27.500 27.5000  17.966 0.002179 **\nResiduals  9 13.776  1.5307                    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nAnalysis of Variance Table\n\nResponse: y3\n          Df Sum Sq Mean Sq F value   Pr(&gt;F)   \nx3         1 27.470 27.4700  17.972 0.002176 **\nResiduals  9 13.756  1.5285                    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nAnalysis of Variance Table\n\nResponse: y4\n          Df Sum Sq Mean Sq F value   Pr(&gt;F)   \nx4         1 27.490 27.4900  18.003 0.002165 **\nResiduals  9 13.742  1.5269                    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nsapply(mods, coef)\n\n                  lm1      lm2       lm3       lm4\n(Intercept) 3.0000909 3.000909 3.0024545 3.0017273\nx1          0.5000909 0.500000 0.4997273 0.4999091\n\nlapply(mods, function(fm) coef(summary(fm)))\n\n$lm1\n             Estimate Std. Error  t value    Pr(&gt;|t|)\n(Intercept) 3.0000909  1.1247468 2.667348 0.025734051\nx1          0.5000909  0.1179055 4.241455 0.002169629\n\n$lm2\n            Estimate Std. Error  t value    Pr(&gt;|t|)\n(Intercept) 3.000909  1.1253024 2.666758 0.025758941\nx2          0.500000  0.1179637 4.238590 0.002178816\n\n$lm3\n             Estimate Std. Error  t value    Pr(&gt;|t|)\n(Intercept) 3.0024545  1.1244812 2.670080 0.025619109\nx3          0.4997273  0.1178777 4.239372 0.002176305\n\n$lm4\n             Estimate Std. Error  t value    Pr(&gt;|t|)\n(Intercept) 3.0017273  1.1239211 2.670763 0.025590425\nx4          0.4999091  0.1178189 4.243028 0.002164602\n\nop &lt;- par(mfrow = c(2, 2), mar = 0.1+c(4,4,1,1), oma =  c(0, 0, 2, 0))\nfor(i in 1:4) {\n  ff[2:3] &lt;- lapply(paste0(c(\"y\",\"x\"), i), as.name)\n  plot(ff, data = anscombe, col = \"red\", pch = 21, bg = \"orange\", cex = 1.2,\n       xlim = c(3, 19), ylim = c(3, 13))\n  abline(mods[[i]], col = \"blue\")\n}\nmtext(\"Anscombe's 4 Regression data sets\", outer = TRUE, cex = 1.5)\n\n\n\n\n\n\n\npar(op)\n\nThe image depicts Anscombe’s quartet, a set of four different datasets that are constructed to have nearly identical simple descriptive statistics (e.g., mean, variance, correlation, and linear regression line) but very different distributions and patterns.\nComparison of the Regression Models:\n\n\n\n\n\n\n\n\n\n\n\nTop Left (Dataset 1)\nTop Right (Dataset 2)\nBottom Left (Dataset 3)\nBottom Right (Dataset 4)\n\n\n\n\nFeatures of data\nThe data points form a roughly linear relationship.\nThe data points form a nonlinear pattern, resembling a curve.\nThere is a strong linear relationship, but one point is an outlier.\nAll the points, except one, are nearly identical, with one extreme outlier on the x-axis.\n\n\nThe relationship between data and regression line\nThe data points fit well with the regression line.\nThough computed to fit linearly, the regression line does not capture this nonlinear relationship well.\nThis single outlier’s presence significantly affects the regression line, shifting it away from the expected fit.\nThe regression line suggests a relationship, but the x-values’ lack of variation means the model is not reliable.\n\n\nThe degree of agreement between the data and the regression line\nThis dataset behaves as expected, showing a good linear fit with minimal deviation.\nThis illustrates that linear regression may not always be the best fit for curved data.\nThis demonstrates the sensitivity of linear regression to outliers.\nThis illustrates how a single influential point can distort a regression analysis.\n\n\n\nEven though all four datasets have similar linear regression results (same slope, intercept, and R-squared values), their visual patterns are significantly different. This highlights the importance of visualizing data before relying on statistical models, as summary statistics alone can be misleading.\n\n\n3. Can you finetune the charts without using other packages (consult RGraphics by Murrell)?\n\nUse a serif font\nTry non-default colors\nUse own plotting character\n\n\n# Scatterplot with refined elements\nx &lt;- c(0.5, 2, 4, 8, 12, 16)\ny1 &lt;- c(1, 1.3, 1.9, 3.4, 3.9, 4.8)\ny2 &lt;- c(4, .8, .5, .45, .4, .3)\n\n# Set up graphical parameters\npar(family=\"serif\", las=1, mar=c(4, 4, 2, 4), cex=0.7) \n\n# Start a new plot\nplot.new()\nplot.window(range(x), c(0, 6))\n\n# Draw lines for y1 and y2 with custom colors\nlines(x, y1, col=\"blue\", lwd=2)\nlines(x, y2, col=\"orangered3\", lwd=2)\n\n# Use custom plotting characters and colors for points\npoints(x, y1, pch=17, cex=2, col=\"darkblue\")   # pch=17: filled triangle\npoints(x, y2, pch=15, cex=2, col=\"orange\")     # pch=15: filled square\n\n# Customize axis colors and text\npar(col=\"gray50\", fg=\"gray50\", col.axis=\"gray50\")\naxis(1, at=seq(0, 16, 4), col.axis=\"forestgreen\", lwd=2)  # Custom x-axis color\naxis(2, at=seq(0, 6, 2), col.axis=\"steelblue\", lwd=2)   # Custom left y-axis color\naxis(4, at=seq(0, 6, 2), col.axis=\"darkorange\", lwd=2)  # Custom right y-axis color\n\n# Add a customized box with specific line width\nbox(bty=\"u\", lwd=2)\n\n# Add axis labels with custom color and size\nmtext(\"Travel Time (s)\", side=1, line=2, cex=0.8, col=\"darkgreen\")\nmtext(\"Responses per Travel\", side=2, line=2, las=0, cex=0.8, col=\"navy\")\nmtext(\"Responses per Second\", side=4, line=2, las=0, cex=0.8, col=\"orangered2\")\n\n# Add a text annotation\ntext(4, 5, \"Bird 131\", col=\"deeppink2\", font=3, cex=2)  # font=3: Italic text\n\n\n\n\n\n\n\n# Reset to default settings\npar(mar=c(5.1, 4.1, 4.1, 2.1), col=\"black\", fg=\"black\", col.axis=\"black\")\n\n\n\n4. How about with ggplot2? (use tidyverse package)\n\n# Load ggplot2\nlibrary(ggplot2)\n\n# Prepare data frame\ndata &lt;- data.frame(\n  x = c(0.5, 2, 4, 8, 12, 16),\n  y1 = c(1, 1.3, 1.9, 3.4, 3.9, 4.8),\n  y2 = c(4, 0.8, 0.5, 0.45, 0.4, 0.3)\n)\n\n# Create charts using ggplot\nggplot(data, aes(x = x)) +\n  \n  # Draw y1 polyline and points\n  geom_line(aes(y = y1), color = \"blue\", linewidth = 1) +  # 使用 linewidth 替換 size\n  geom_point(aes(y = y1), shape = 17, size = 3, color = \"darkblue\") +\n  \n  # Draw y2 polyline and points\n  geom_line(aes(y = y2), color = \"orangered3\", linewidth = 1) +  # 使用 linewidth 替換 size\n  geom_point(aes(y = y2), shape = 15, size = 3, color = \"orange\") +\n  \n  # Customize x- and y-axis labels and colors\n  scale_x_continuous(name = \"Travel Time (s)\", breaks = seq(0, 16, 4), limits = c(0, 16), \n                     labels = seq(0, 16, 4), expand = c(0, 0)) +\n  scale_y_continuous(\n    name = \"Responses per Travel\",\n    sec.axis = sec_axis(~ ., name = \"Responses per Second\", breaks = seq(0, 6, 2))\n  ) +\n  \n  # Annotate text\n  annotate(\"text\", x = 4, y = 5, label = \"Bird 131\", color = \"deeppink2\", family = \"serif\", fontface = \"italic\", size = 6) +\n  \n  # Theme customization, adjust axis and text color\n  theme_minimal(base_family = \"serif\") +\n  theme(\n    axis.title.x = element_text(size = 12, color = \"darkgreen\"),\n    axis.title.y = element_text(size = 12, color = \"navy\"),\n    axis.text.x = element_text(color = \"forestgreen\"),\n    axis.text.y = element_text(color = \"steelblue\"),\n    axis.text.y.right = element_text(color = \"orangered2\"),\n    axis.title.y.right = element_text(size = 12, color = \"orangered2\"),\n    panel.border = element_blank(),\n    axis.line = element_line(color = \"gray50\", linewidth = 1)  # 使用 linewidth 替換 size\n  )\n\n\n\n\n\n\n\n\n\n\n5. Pre-hackathon by team:\n\nTeam work: Replicate the Scatterplot matrix below (hint: Acquire data using the following codes)\nSend the codes to the TA. The first team delivering the code and chart will win a prize (by time stamp and product)\n\nDownload COVID data from OWID GitHub owidall = read.csv(“https://github.com/owid/covid-19- data/blob/master/public/data/owid-covid-data.csv?raw=true”) # Deselect cases/rows with OWID owidall = owidall[!grepl(“^OWID”, owidall$iso_code), ] # Subset by continent: Europe owideu = subset(owidall, continent==“Europe”)\n\n#匯入/讀取owideu.xlsx\nlibrary(readxl)\nowideu_data &lt;- read_excel(\"owideu.xlsx\")\n\n#檢查owideu_data檔案\nhead(owideu_data)\n\n# A tibble: 6 × 67\n  iso_code continent location date      total_cases new_cases new_cases_smoothed\n  &lt;chr&gt;    &lt;chr&gt;     &lt;chr&gt;    &lt;chr&gt;           &lt;dbl&gt;     &lt;dbl&gt;              &lt;dbl&gt;\n1 ALB      Europe    Albania  2020-01-…           0         0                 NA\n2 ALB      Europe    Albania  2020-01-…           0         0                 NA\n3 ALB      Europe    Albania  2020-01-…           0         0                 NA\n4 ALB      Europe    Albania  2020-01-…           0         0                 NA\n5 ALB      Europe    Albania  2020-01-…           0         0                 NA\n6 ALB      Europe    Albania  2020-01-…           0         0                  0\n# ℹ 60 more variables: total_deaths &lt;dbl&gt;, new_deaths &lt;dbl&gt;,\n#   new_deaths_smoothed &lt;dbl&gt;, total_cases_per_million &lt;dbl&gt;,\n#   new_cases_per_million &lt;dbl&gt;, new_cases_smoothed_per_million &lt;dbl&gt;,\n#   total_deaths_per_million &lt;dbl&gt;, new_deaths_per_million &lt;dbl&gt;,\n#   new_deaths_smoothed_per_million &lt;dbl&gt;, reproduction_rate &lt;dbl&gt;,\n#   icu_patients &lt;lgl&gt;, icu_patients_per_million &lt;lgl&gt;, hosp_patients &lt;lgl&gt;,\n#   hosp_patients_per_million &lt;lgl&gt;, weekly_icu_admissions &lt;lgl&gt;, …\n\nView(owideu_data)\n\n#提取owideu_data中的date欄位並轉換成日期格式\ndate_vector &lt;- as.Date(owideu_data$date) \n\n\nlength(date_vector)\n\n[1] 84123\n\nnrow(owideu_data)     # 檢查 owideu_data 資料框的行數\n\n[1] 84123\n\n#長度和行數要一樣才能合併\n\n#使用 mutate() 來新增變數\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nowideu_data &lt;- owideu_data %&gt;%\n  mutate(date_vector = date_vector)\n\n\n#匯出owideu_datat成execl檔\n# install.packages(\"writexl\")\n# library(writexl)\n# write_xlsx(owideu_data, \"owideu_data.xlsx\")\n\n#x= owideu_data$date_vector\n#y= owideu_data$new_deaths\n\n# 設定標籤方向、邊距與文字大小\npar(family=\"serif\", las=1, mar=c(5, 5, 2, 2), cex=.8) \nplot.new()\n\n# 使用日期格式繪圖範圍\nplot.window(range(owideu_data$date_vector), range(owideu_data$new_deaths, na.rm=TRUE))\n\n# 繪製資料點\npoints(owideu_data$date_vector, owideu_data$new_deaths, pch=16, col=\"deeppink2\", cex=0.6)\n\n# 繪製 x 軸和 y 軸\naxis(1, at=seq(min(owideu_data$date_vector), max(owideu_data$date_vector), by=\"2 months\"), las=2, cex.axis=0.8, labels=format(seq(min(owideu_data$date_vector), max(owideu_data$date_vector), by=\"2 months\"), \"%Y-%m\"))\naxis(2, at=seq(0, 10000, 2000), las=2, cex.axis=0.8)\n\n# 繪製圖框\nbox(bty=\"o\")\n\n# 添加標籤\nmtext(\"Date\", side=1, line=3.5, cex=1)  # x 軸標籤\nmtext(\"COVID Deaths in Europe (Daily)\", side=2, line=3, las=0, cex=1)  # y 軸標籤\n\n# 添加國家標註 (根據觀察點的位置手動設定)\ntext(as.Date(\"2020-04-01\"), 5800, \"Spain\", cex=0.8)\ntext(as.Date(\"2020-04-15\"), 4800, \"Spain\", cex=0.8)\ntext(as.Date(\"2020-12-01\"), 6600, \"Germany\", cex=0.8)\ntext(as.Date(\"2021-10-15\"), 4500, \"Ukraine\", cex=0.8)\ntext(as.Date(\"2022-12-15\"), 1300, \"Germany\", cex=0.8)\ntext(as.Date(\"2023-09-01\"), 300, \"Italy\", cex=0.8)\n\n\n\n\n\n\n\n# 恢復預設繪圖參數\npar(mar=c(5.1, 4.1, 4.1, 2.1), col=\"black\", fg=\"black\", col.axis=\"black\")",
    "crumbs": [
      "Home",
      "EPPS6356",
      "Assignment 3"
    ]
  },
  {
    "objectID": "DV_assignment01.html",
    "href": "DV_assignment01.html",
    "title": "Assignment 1",
    "section": "",
    "text": "1. Try Anscombe’s examples\n\n## Data Visualization\n## Objective: Identify data or model problems using visualization\n## Anscombe (1973) Quartlet\n\ndata(anscombe)  # Load Anscombe's data\nView(anscombe) # View the data\nsummary(anscombe)\n\n       x1             x2             x3             x4           y1        \n Min.   : 4.0   Min.   : 4.0   Min.   : 4.0   Min.   : 8   Min.   : 4.260  \n 1st Qu.: 6.5   1st Qu.: 6.5   1st Qu.: 6.5   1st Qu.: 8   1st Qu.: 6.315  \n Median : 9.0   Median : 9.0   Median : 9.0   Median : 8   Median : 7.580  \n Mean   : 9.0   Mean   : 9.0   Mean   : 9.0   Mean   : 9   Mean   : 7.501  \n 3rd Qu.:11.5   3rd Qu.:11.5   3rd Qu.:11.5   3rd Qu.: 8   3rd Qu.: 8.570  \n Max.   :14.0   Max.   :14.0   Max.   :14.0   Max.   :19   Max.   :10.840  \n       y2              y3              y4        \n Min.   :3.100   Min.   : 5.39   Min.   : 5.250  \n 1st Qu.:6.695   1st Qu.: 6.25   1st Qu.: 6.170  \n Median :8.140   Median : 7.11   Median : 7.040  \n Mean   :7.501   Mean   : 7.50   Mean   : 7.501  \n 3rd Qu.:8.950   3rd Qu.: 7.98   3rd Qu.: 8.190  \n Max.   :9.260   Max.   :12.74   Max.   :12.500  \n\n## Simple version\nplot(anscombe$x1,anscombe$y1)\nsummary(anscombe)\n\n       x1             x2             x3             x4           y1        \n Min.   : 4.0   Min.   : 4.0   Min.   : 4.0   Min.   : 8   Min.   : 4.260  \n 1st Qu.: 6.5   1st Qu.: 6.5   1st Qu.: 6.5   1st Qu.: 8   1st Qu.: 6.315  \n Median : 9.0   Median : 9.0   Median : 9.0   Median : 8   Median : 7.580  \n Mean   : 9.0   Mean   : 9.0   Mean   : 9.0   Mean   : 9   Mean   : 7.501  \n 3rd Qu.:11.5   3rd Qu.:11.5   3rd Qu.:11.5   3rd Qu.: 8   3rd Qu.: 8.570  \n Max.   :14.0   Max.   :14.0   Max.   :14.0   Max.   :19   Max.   :10.840  \n       y2              y3              y4        \n Min.   :3.100   Min.   : 5.39   Min.   : 5.250  \n 1st Qu.:6.695   1st Qu.: 6.25   1st Qu.: 6.170  \n Median :8.140   Median : 7.11   Median : 7.040  \n Mean   :7.501   Mean   : 7.50   Mean   : 7.501  \n 3rd Qu.:8.950   3rd Qu.: 7.98   3rd Qu.: 8.190  \n Max.   :9.260   Max.   :12.74   Max.   :12.500  \n\n# Create four model objects\nlm1 &lt;- lm(y1 ~ x1, data=anscombe)\nsummary(lm1)\n\n\nCall:\nlm(formula = y1 ~ x1, data = anscombe)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1.92127 -0.45577 -0.04136  0.70941  1.83882 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)   \n(Intercept)   3.0001     1.1247   2.667  0.02573 * \nx1            0.5001     0.1179   4.241  0.00217 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.237 on 9 degrees of freedom\nMultiple R-squared:  0.6665,    Adjusted R-squared:  0.6295 \nF-statistic: 17.99 on 1 and 9 DF,  p-value: 0.00217\n\nlm2 &lt;- lm(y2 ~ x2, data=anscombe)\nsummary(lm2)\n\n\nCall:\nlm(formula = y2 ~ x2, data = anscombe)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-1.9009 -0.7609  0.1291  0.9491  1.2691 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)   \n(Intercept)    3.001      1.125   2.667  0.02576 * \nx2             0.500      0.118   4.239  0.00218 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.237 on 9 degrees of freedom\nMultiple R-squared:  0.6662,    Adjusted R-squared:  0.6292 \nF-statistic: 17.97 on 1 and 9 DF,  p-value: 0.002179\n\nlm3 &lt;- lm(y3 ~ x3, data=anscombe)\nsummary(lm3)\n\n\nCall:\nlm(formula = y3 ~ x3, data = anscombe)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-1.1586 -0.6146 -0.2303  0.1540  3.2411 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)   \n(Intercept)   3.0025     1.1245   2.670  0.02562 * \nx3            0.4997     0.1179   4.239  0.00218 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.236 on 9 degrees of freedom\nMultiple R-squared:  0.6663,    Adjusted R-squared:  0.6292 \nF-statistic: 17.97 on 1 and 9 DF,  p-value: 0.002176\n\nlm4 &lt;- lm(y4 ~ x4, data=anscombe)\nsummary(lm4)\n\n\nCall:\nlm(formula = y4 ~ x4, data = anscombe)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-1.751 -0.831  0.000  0.809  1.839 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)   \n(Intercept)   3.0017     1.1239   2.671  0.02559 * \nx4            0.4999     0.1178   4.243  0.00216 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.236 on 9 degrees of freedom\nMultiple R-squared:  0.6667,    Adjusted R-squared:  0.6297 \nF-statistic:    18 on 1 and 9 DF,  p-value: 0.002165\n\nplot(anscombe$x1,anscombe$y1)\nabline(coefficients(lm1))\n\n\n\n\n\n\n\nplot(anscombe$x2,anscombe$y2)\nabline(coefficients(lm2))\n\n\n\n\n\n\n\nplot(anscombe$x3,anscombe$y3)\nabline(coefficients(lm3))\n\n\n\n\n\n\n\nplot(anscombe$x4,anscombe$y4)\nabline(coefficients(lm4))\n\n\n\n\n\n\n\n## Fancy version (per help file)\n\nff &lt;- y ~ x\nmods &lt;- setNames(as.list(1:4), paste0(\"lm\", 1:4))\n\n# Plot using for loop\nfor(i in 1:4) {\n  ff[2:3] &lt;- lapply(paste0(c(\"y\",\"x\"), i), as.name)\n  ## or   ff[[2]] &lt;- as.name(paste0(\"y\", i))\n  ##      ff[[3]] &lt;- as.name(paste0(\"x\", i))\n  mods[[i]] &lt;- lmi &lt;- lm(ff, data = anscombe)\n  print(anova(lmi))\n}\n\nAnalysis of Variance Table\n\nResponse: y1\n          Df Sum Sq Mean Sq F value  Pr(&gt;F)   \nx1         1 27.510 27.5100   17.99 0.00217 **\nResiduals  9 13.763  1.5292                   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nAnalysis of Variance Table\n\nResponse: y2\n          Df Sum Sq Mean Sq F value   Pr(&gt;F)   \nx2         1 27.500 27.5000  17.966 0.002179 **\nResiduals  9 13.776  1.5307                    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nAnalysis of Variance Table\n\nResponse: y3\n          Df Sum Sq Mean Sq F value   Pr(&gt;F)   \nx3         1 27.470 27.4700  17.972 0.002176 **\nResiduals  9 13.756  1.5285                    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nAnalysis of Variance Table\n\nResponse: y4\n          Df Sum Sq Mean Sq F value   Pr(&gt;F)   \nx4         1 27.490 27.4900  18.003 0.002165 **\nResiduals  9 13.742  1.5269                    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nsapply(mods, coef)  # Note the use of this function\n\n                  lm1      lm2       lm3       lm4\n(Intercept) 3.0000909 3.000909 3.0024545 3.0017273\nx1          0.5000909 0.500000 0.4997273 0.4999091\n\nlapply(mods, function(fm) coef(summary(fm)))\n\n$lm1\n             Estimate Std. Error  t value    Pr(&gt;|t|)\n(Intercept) 3.0000909  1.1247468 2.667348 0.025734051\nx1          0.5000909  0.1179055 4.241455 0.002169629\n\n$lm2\n            Estimate Std. Error  t value    Pr(&gt;|t|)\n(Intercept) 3.000909  1.1253024 2.666758 0.025758941\nx2          0.500000  0.1179637 4.238590 0.002178816\n\n$lm3\n             Estimate Std. Error  t value    Pr(&gt;|t|)\n(Intercept) 3.0024545  1.1244812 2.670080 0.025619109\nx3          0.4997273  0.1178777 4.239372 0.002176305\n\n$lm4\n             Estimate Std. Error  t value    Pr(&gt;|t|)\n(Intercept) 3.0017273  1.1239211 2.670763 0.025590425\nx4          0.4999091  0.1178189 4.243028 0.002164602\n\n# Preparing for the plots\nop &lt;- par(mfrow = c(2, 2), mar = 0.1+c(4,4,1,1), oma =  c(0, 0, 2, 0))\n\n# Plot charts using for loop\nfor(i in 1:4) {\n  ff[2:3] &lt;- lapply(paste0(c(\"y\",\"x\"), i), as.name)\n  plot(ff, data = anscombe, col = \"red\", pch = 21, bg = \"orange\", cex = 1.2,\n       xlim = c(3, 19), ylim = c(3, 13))\n  abline(mods[[i]], col = \"blue\")\n}\nmtext(\"Anscombe's 4 Regression data sets\", outer = TRUE, cex = 1.5)\n\n\n\n\n\n\n\npar(op)\n\n\n\n2. Google “generative art”. Cite some examples.\n\nAuthor: Hieroglyphica (aka Jason Sholl)Source: At the Forefront of Generative Art with Hieroglyphica\n Source: Generative Artists Club – GenArtClub\n Author: James Pricer, DNA Data Portrait of undefined a CoderSource: New Austin Gallery Will Focus on Generative Art\n\n\n\n\nAuthor: Hao Hua\nSource: Generative Art\n\n\n\n\n3. Run Fall.R\n\nGive your own colors (e.g. Winter).\nExport the file and post on your GitHub website.\n\nset color=“#56B4E9”\n\n# 設置 CRAN 鏡像\noptions(repos = c(CRAN = \"https://cloud.r-project.org\"))\n\n# 安裝所需的套件\nif (!require(\"gsubfn\")) install.packages(\"gsubfn\")\n\nLoading required package: gsubfn\n\n\nLoading required package: proto\n\nif (!require(\"proto\")) install.packages(\"proto\")\nif (!require(\"tidyverse\")) install.packages(\"tidyverse\")\n\nLoading required package: tidyverse\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.2     ✔ tibble    3.3.0\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.1.0     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n## Data Visualization\n## Objective: Create graphics with R\n## Title: Fall color\n# Credit: https://fronkonstin.com\n\n# Install packages\ninstall.packages(c(\"gsubfn\", \"proto\", \"tidyverse\"))\n\nWarning: packages 'gsubfn', 'proto', 'tidyverse' are in use and will not be\ninstalled\n\nlibrary(gsubfn)\nlibrary(tidyverse)\n\n# Define elements in plant art\n# Each image corresponds to a different axiom, rules, angle and depth\n\n# Leaf of Fall\n\naxiom=\"X\"\nrules=list(\"X\"=\"F-[[X]+X]+F[+FX]-X\", \"F\"=\"FF\")\nangle=22.5\ndepth=6\n\n\nfor (i in 1:depth) axiom=gsubfn(\".\", rules, axiom)\n\nactions=str_extract_all(axiom, \"\\\\d*\\\\+|\\\\d*\\\\-|F|L|R|\\\\[|\\\\]|\\\\|\") %&gt;% unlist\n\nstatus=data.frame(x=numeric(0), y=numeric(0), alfa=numeric(0))\npoints=data.frame(x1 = 0, y1 = 0, x2 = NA, y2 = NA, alfa=90, depth=1)\n\n\n# Generating data\n# Note: may take a minute or two\n\nfor (action in actions)\n{\n  if (action==\"F\")\n  {\n    x=points[1, \"x1\"]+cos(points[1, \"alfa\"]*(pi/180))\n    y=points[1, \"y1\"]+sin(points[1, \"alfa\"]*(pi/180))\n    points[1,\"x2\"]=x\n    points[1,\"y2\"]=y\n    data.frame(x1 = x, y1 = y, x2 = NA, y2 = NA,\n               alfa=points[1, \"alfa\"],\n               depth=points[1,\"depth\"]) %&gt;% rbind(points)-&gt;points\n  }\n  if (action %in% c(\"+\", \"-\")){\n    alfa=points[1, \"alfa\"]\n    points[1, \"alfa\"]=eval(parse(text=paste0(\"alfa\",action, angle)))\n  }\n  if(action==\"[\"){\n    data.frame(x=points[1, \"x1\"], y=points[1, \"y1\"], alfa=points[1, \"alfa\"]) %&gt;%\n      rbind(status) -&gt; status\n    points[1, \"depth\"]=points[1, \"depth\"]+1\n  }\n  \n  if(action==\"]\"){\n    depth=points[1, \"depth\"]\n    points[-1,]-&gt;points\n    data.frame(x1=status[1, \"x\"], y1=status[1, \"y\"], x2=NA, y2=NA,\n               alfa=status[1, \"alfa\"],\n               depth=depth-1) %&gt;%\n      rbind(points) -&gt; points\n    status[-1,]-&gt;status\n  }\n}\n\nggplot() +\n  geom_segment(aes(x = x1, y = y1, xend = x2, yend = y2),\n               lineend = \"round\",\n               color=\"#56B4E9\", # Set your own Fall color?\n               data=na.omit(points)) +\n  coord_fixed(ratio = 1) +\n  theme_void() # No grid nor axes\n\n\n\n\n\n\n\n\n\n\n4. Write a critique on a chart in published work (book/article/news website)s\n\n\n\n\n\n\nSource: 肺癌成新國病 各期數治療成效大不同！專家：早期發現術後存活率逾 9 成\n\nReview:\nThis bar chart shows Taiwan’s five-year survival rate (blue) and prevalence rate (orange) of lung cancer in 2014. For public health practitioners, this bar chart highlights the sharp decline in five-year survival rates as the lung cancer stage increases, while conversely, the number of patients increases significantly. It reveals the importance of cancer screening (early detection, early treatment) and the unfortunate fact that most people wait until the last stage to be diagnosed. This chart can be used for health education. On the other hand, although the configuration of the bar chart is readable, it is difficult for laypeople without a medical background to understand the relationship between the change in the five-year survival rate (blue) and the change in the proportion of patients (orange).\n\n\n \nSource: 台灣乳癌發生率監測\n\nReview:\nThis chart illustrates the correlation between breast cancer incidence and age by birth generation in Taiwan and the United States. Different colors denote different birth generations; additionally, on the original webpage, left-clicking each age group will prompt an explanation of the corresponding data analysis results (see the second image for details). These two features assist readers in comprehending the chart’s significance. Charts for Taiwan and the United States are also presented simultaneously, enabling readers to compare the disparities between the two countries effortlessly. This chart demonstrates that in Taiwan, later generations have a higher rate of breast cancer at the same age, while this phenomenon is not observed in the United States.",
    "crumbs": [
      "Home",
      "EPPS6356",
      "Assignment 1"
    ]
  },
  {
    "objectID": "DC_assignment03.html",
    "href": "DC_assignment03.html",
    "title": "Assignment 3: Mapping Census data",
    "section": "",
    "text": "Use tidycensus to retrieve ACS 2023 5-year estimates, create a tidy dataset, and produce one map and one table with short interpretation.",
    "crumbs": [
      "Home",
      "EPPS6302",
      "Assignment 3"
    ]
  },
  {
    "objectID": "DC_assignment03.html#setup",
    "href": "DC_assignment03.html#setup",
    "title": "Assignment 3: Mapping Census data",
    "section": "1. Setup",
    "text": "1. Setup\n\nObtain a Census API key (https://api.census.gov/data/key_signup.html).\nIn R: census_api_key(“YOUR_KEY”, install = FALSE).\nInstall and load R packges: tidycensus, tigris, sf, dplyr, ggplot2, readr.\n\n\n# Packages\nlibrary(tidycensus)\nlibrary(tigris)\n\nTo enable caching of data, set `options(tigris_use_cache = TRUE)`\nin your R script or .Rprofile.\n\nlibrary(sf)\n\nLinking to GEOS 3.13.1, GDAL 3.11.0, PROJ 9.6.0; sf_use_s2() is TRUE\n\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(ggplot2)\nlibrary(readr)\n\noptions(tigris_use_cache = TRUE)\n\n# 1) API key (uncomment and paste your key)\ncensus_api_key(\"5f1dc6a21e748ab03bc00d3a101977c8c84d3e1c\", install = FALSE)\n\nTo install your API key for use in future sessions, run this function with `install = TRUE`.",
    "crumbs": [
      "Home",
      "EPPS6302",
      "Assignment 3"
    ]
  },
  {
    "objectID": "DC_assignment03.html#choose-a-geography-and-variables",
    "href": "DC_assignment03.html#choose-a-geography-and-variables",
    "title": "Assignment 3: Mapping Census data",
    "section": "2. Choose a geography and variable(s)",
    "text": "2. Choose a geography and variable(s)\n\nGeography: one of state, county, tract, or block group (within a state).\nVariables: pick at least two ACS variables (e.g., B19013_001 median HH income; B17001_002people below poverty).\nUse load_variables(2023, “acs5”, cache = TRUE) to search codes.\n\n\n# 2) Explore variables\nvars &lt;- load_variables(2023, \"acs5\", cache = TRUE)\n# View a few example codes\nvars |&gt; dplyr::filter(grepl(\"^B19\", name)) |&gt; dplyr::slice_head(n = 10)\n\n# A tibble: 10 × 4\n   name        label                                concept            geography\n   &lt;chr&gt;       &lt;chr&gt;                                &lt;chr&gt;              &lt;chr&gt;    \n 1 B19001A_001 Estimate!!Total:                     Household Income … tract    \n 2 B19001A_002 Estimate!!Total:!!Less than $10,000  Household Income … tract    \n 3 B19001A_003 Estimate!!Total:!!$10,000 to $14,999 Household Income … tract    \n 4 B19001A_004 Estimate!!Total:!!$15,000 to $19,999 Household Income … tract    \n 5 B19001A_005 Estimate!!Total:!!$20,000 to $24,999 Household Income … tract    \n 6 B19001A_006 Estimate!!Total:!!$25,000 to $29,999 Household Income … tract    \n 7 B19001A_007 Estimate!!Total:!!$30,000 to $34,999 Household Income … tract    \n 8 B19001A_008 Estimate!!Total:!!$35,000 to $39,999 Household Income … tract    \n 9 B19001A_009 Estimate!!Total:!!$40,000 to $44,999 Household Income … tract    \n10 B19001A_010 Estimate!!Total:!!$45,000 to $49,999 Household Income … tract    \n\n# 3) Parameters (EDIT ME)\nstate_abbr &lt;- \"TX\"\ngeo_level  &lt;- \"county\"   # options: state, county, tract, block group\nmy_vars    &lt;- c(income = \"B19013_001\", poverty = \"B17001_002\")\nyear_acs   &lt;- 2023\nsurvey     &lt;- \"acs5\"",
    "crumbs": [
      "Home",
      "EPPS6302",
      "Assignment 3"
    ]
  },
  {
    "objectID": "DC_assignment03.html#download-data-with-geometry",
    "href": "DC_assignment03.html#download-data-with-geometry",
    "title": "Assignment 3: Mapping Census data",
    "section": "3. Download data (with geometry)",
    "text": "3. Download data (with geometry)\n\nUse get_acs() with your geography and variables.\nKeep estimate and moe (margins of error).\n\n\n# 4) Download\nacs &lt;- get_acs(\n  geography = geo_level,\n  variables = my_vars,\n  state = state_abbr,\n  year = year_acs,\n  survey = survey,\n  geometry = TRUE\n)\n\nGetting data from the 2019-2023 5-year ACS\n\n# 5) Wide format for convenience\nacs_wide &lt;- acs |&gt;\n  tidyr::pivot_wider(\n    id_cols = c(GEOID, NAME, geometry),\n    names_from = variable,\n    values_from = c(estimate, moe)\n  )",
    "crumbs": [
      "Home",
      "EPPS6302",
      "Assignment 3"
    ]
  },
  {
    "objectID": "DC_assignment03.html#deliverables",
    "href": "DC_assignment03.html#deliverables",
    "title": "Assignment 3: Mapping Census data",
    "section": "4. Deliverables",
    "text": "4. Deliverables\n\nMap: choropleth of one variable (with a clear legend and title).\nTable: top/bottom 10 areas by the other variable (include MOE).\nInterpret map and table data\n\n\n# 6) Map (edit titles/theme)\nggplot(acs_wide) +\n  geom_sf(aes(fill = estimate_income), color = NA) +\n  scale_fill_viridis_c(name = \"Median HH Income\") +\n  labs(title = paste0(\"ACS \", year_acs, \" 5-year: Median Income — \", state_abbr, \" (\", geo_level, \")\"),\n       caption = \"Source: U.S. Census Bureau via tidycensus\") +\n  theme_minimal()\n\n\n\n\n\n\n\n# 7) Table (top/bottom by poverty count)\ntop10 &lt;- acs_wide |&gt;\n  arrange(desc(estimate_poverty)) |&gt;\n  select(NAME, estimate_poverty, moe_poverty) |&gt;\n  slice_head(n = 10)\n\nbottom10 &lt;- acs_wide |&gt;\n  arrange(estimate_poverty) |&gt;\n  select(NAME, estimate_poverty, moe_poverty) |&gt;\n  slice_head(n = 10)\n\ntop10\n\nSimple feature collection with 10 features and 3 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -106.6456 ymin: 25.83738 xmax: -94.9085 ymax: 33.43045\nGeodetic CRS:  NAD83\n# A tibble: 10 × 4\n   NAME                  estimate_poverty moe_poverty                   geometry\n   &lt;chr&gt;                            &lt;dbl&gt;       &lt;dbl&gt;         &lt;MULTIPOLYGON [°]&gt;\n 1 Harris County, Texas            749481       15891 (((-94.97839 29.68365, -9…\n 2 Dallas County, Texas            359950       10475 (((-97.03852 32.56, -97.0…\n 3 Bexar County, Texas             294002        8323 (((-98.80655 29.69071, -9…\n 4 Hidalgo County, Texas           237121        8739 (((-98.58634 26.25824, -9…\n 5 Tarrant County, Texas           229884        7849 (((-97.55053 32.56258, -9…\n 6 El Paso County, Texas           160998        7148 (((-106.6455 31.89867, -1…\n 7 Travis County, Texas            140926        6636 (((-98.15927 30.37665, -9…\n 8 Cameron County, Texas           102583        4345 (((-97.24047 26.41119, -9…\n 9 Collin County, Texas             69846        4614 (((-96.8441 32.98891, -96…\n10 Denton County, Texas             65649        4233 (((-97.39826 32.99996, -9…\n\nbottom10\n\nSimple feature collection with 10 features and 3 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -103.9839 ymin: 26.598 xmax: -97.29015 ymax: 36.05771\nGeodetic CRS:  NAD83\n# A tibble: 10 × 4\n   NAME                   estimate_poverty moe_poverty                  geometry\n   &lt;chr&gt;                             &lt;dbl&gt;       &lt;dbl&gt;        &lt;MULTIPOLYGON [°]&gt;\n 1 Kenedy County, Texas                  3           5 (((-97.39839 26.86789, -…\n 2 Loving County, Texas                  5           7 (((-103.9839 31.99411, -…\n 3 King County, Texas                   29          26 (((-100.5187 33.83565, -…\n 4 Borden County, Texas                 35          28 (((-101.6913 32.96184, -…\n 5 Sterling County, Texas               37          25 (((-101.267 31.64419, -1…\n 6 Roberts County, Texas                50          35 (((-101.086 35.82337, -1…\n 7 Kent County, Texas                   56          32 (((-101.0389 33.30571, -…\n 8 McMullen County, Texas               57          47 (((-98.80251 28.10305, -…\n 9 Terrell County, Texas                70          46 (((-102.5669 30.28327, -…\n10 Glasscock County, Tex…               91          67 (((-101.7761 32.08693, -…\n\n# 8) Save outputs (optional)\n# readr::write_csv(st_drop_geometry(acs_wide), \"acs_data.csv\")\n\n\nInterpretation\nThe choropleth map of Texas counties illustrates the distribution of median household income (ACS 2023 5-year estimates). The results show a clear geographic divide: counties around major metropolitan areas such as Austin, Dallas, and Houston generally report higher incomes, while counties along the southern border and rural West Texas exhibit much lower household incomes. This highlights substantial urban–rural and regional disparities in economic well-being across the state.\nThe tables rank counties by the estimated number of people living below the poverty line. The top 10 counties (e.g., Harris, Dallas, Bexar) contain the largest absolute numbers of individuals in poverty. These are the most populous counties, which means that even with relatively high median incomes, the sheer size of the population results in large numbers of residents living in poverty. Conversely, the bottom 10 counties (e.g., Kenedy, Loving, King) report only a handful of people in poverty. However, these counties are extremely small in population, and the margins of error (MOE) are often larger than or close to the estimates themselves, making these figures less reliable.\nIn summary, the map highlights regional disparities in income levels, while the tables reveal that poverty in absolute numbers is concentrated in Texas’s largest urban counties, and very small counties show unstable estimates due to limited sample sizes.",
    "crumbs": [
      "Home",
      "EPPS6302",
      "Assignment 3"
    ]
  },
  {
    "objectID": "DC_assignment03.html#post-output-on-website-titled-assignment-3-mapping-census-data",
    "href": "DC_assignment03.html#post-output-on-website-titled-assignment-3-mapping-census-data",
    "title": "Assignment 3: Mapping Census data",
    "section": "5. Post output on website titled Assignment 3: Mapping Census data",
    "text": "5. Post output on website titled Assignment 3: Mapping Census data\nSee this page.",
    "crumbs": [
      "Home",
      "EPPS6302",
      "Assignment 3"
    ]
  },
  {
    "objectID": "DC_assignment01.html",
    "href": "DC_assignment01.html",
    "title": "Assignment 1",
    "section": "",
    "text": "Shiu-Ting’s website was built using RStudio Quarto. The theme is customized from the default one provided by Quarto. The navigation bar includes links to the website’s Homepage (Home), the author’s profile page with CV (about), and the author’s GitHub (GitHub icon). The sidebar displays assignments from three data-related classes – EPPS6356, EPPS6354, & EPPS6302 – taught by Dr. Ho at the University of Texas at Dallas.",
    "crumbs": [
      "Home",
      "EPPS6302",
      "Assignment 1"
    ]
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Shiu-Ting Ling",
    "section": "",
    "text": "A graduate student enrolled in the third semester of the SDAR program.\n\nCV"
  },
  {
    "objectID": "DataFramed320.html",
    "href": "DataFramed320.html",
    "title": "The Next Industrial Revolution is Industrial AI - Review",
    "section": "",
    "text": "Review\nThe podcast “The Next Industrial Revolution is Industrial AI” features a discussion between Barbara Humpton, Siemens USA CEO, and Olympia Brikis, Director of Industrial AI, on AI’s impact on manufacturing, innovation, productivity, workforce, and the industry’s future.\nThe talk starts by positioning industrial AI as succeeding earlier revolutions like electrification and automation. Unlike consumer AI, which focuses on convenience, industrial AI handles proprietary data, complex systems, and high-stakes decisions. Humpton and Brikis cite examples of AI transforming operations: in automotive, visual inspection ensures quality; Siemens’ factories use predictive maintenance and automation to free workers for cognitive tasks; Jet Zero’s aircraft employs Siemens’ generative AI and digital twin tech for efficiency and sustainability.\nBeyond technical advances, speakers highlight the human side of industrial AI. Automation boosts output without job losses, empowering workers with AI copilots for higher-level tasks. They discuss adoption challenges like access to capital and training for small and medium enterprises. Success depends on technology and workers’ openness, curiosity, and engagement with new tools.\nWhat stands out in this discussion is the balance between innovation and inclusivity. Industrial AI is not just shown as a technical upgrade but as a collaborative transformation between people and machines. The examples of night-shift workers relying on AI copilots, or training programs made for new employees, show how AI can reduce stress, improve job satisfaction, and expand access to industrial opportunities.\nIn conclusion, this talk envisions industrial AI as a major driver of progress, highlighting its role in fostering creativity, resilience, and growth alongside efficiency. Success in adopting AI globally depends on balancing innovation with workforce development, ensuring technology empowers rather than excludes. The dialogue between Humpton and Brikis shows that the “next industrial revolution” will be shaped by human adaptability as much as technological breakthroughs."
  },
  {
    "objectID": "DC_assignment02.html",
    "href": "DC_assignment02.html",
    "title": "Assignment 2",
    "section": "",
    "text": "Search “Trump”, “Harris”, and “election” on Google Trend website in (See bellowed plot).\n\n\n\n\n\nDownload the Google Trend data in csv file.\n\n\n\n\n\nlibrary(readxl)\nlibrary(dplyr)\nlibrary(stringr)\nlibrary(zoo)        # as.yearmon() 讓 \"YYYY-MM\" 轉成月份日期\n\n\n# 1) 讀檔：跳過前兩列的說明列\nraw &lt;- read_excel(\"TrumpHarrisElection_download.xlsx\",\n                  sheet = \"TrumpHarrisElection\", skip = 2, col_names = FALSE)\nnames(raw) &lt;- c(\"date\",\"Trump\",\"Harris\",\"election\")\n\n# 2) 清理：僅保留像 2004-01 的列，處理 \"&lt;1\"\ndf &lt;- raw %&gt;%\n  mutate(date = str_trim(as.character(date))) %&gt;%     # 去空白，確保是字串\n  filter(str_detect(date, \"^\\\\d{4}-\\\\d{2}$\")) %&gt;%     # 只留 YYYY-MM\n  mutate(\n    # 把 YYYY-MM 變成每月的第一天（Date 類型）\n    date = as.Date(as.yearmon(date)),\n    # 把 \"&lt;1\" 變 0，再轉數值\n    across(c(Trump, Harris, election), ~ as.numeric(str_replace(.x, \"&lt;1\", \"0\")))\n  ) %&gt;%\n  arrange(date)\n\n# 3) 起訖時間\nstart_date &lt;- min(df$date)\nend_date   &lt;- max(df$date)\nstart_date; end_date\n\n[1] \"2004-01-01\"\n\n\n[1] \"2025-09-01\"\n\n\nThe time range of the dataset is from 2004-01-01 to 2025-09-01.\n\n\n\n\n# 4) 時間間隔（天），確認是否為月度資料\ngap_days &lt;- diff(df$date)\nsummary(gap_days)\n\nTime differences in days\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  28.00   30.00   31.00   30.44   31.00   31.00 \n\n# 也可用「月份」為單位檢查\ngap_months &lt;- diff(as.yearmon(df$date)) * 12\nsummary(gap_months)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n      1       1       1       1       1       1 \n\n\n\nThe data are collected on a monthly basis, with most intervals being 30 or 31 days.\nThe summary shows that the minimum interval is 28 days and the maximum is 31 days, which corresponds to the varying number of days in each month.\n\n\n\n\n\n\n\nSearching “Trump”,“Harris”, & “election” on Google Trends\n\n# 這段程式碼會顯示，但不會執行\n\n#install.packages(\"gtrendsR\")\n\nlibrary(gtrendsR)\n\n# ---- \"Trump\",\"Harris\",\"election\" 查詢 (不限時間地點) -----\nTrumpHarrisElection = gtrends(c(\"Trump\",\"Harris\",\"election\"), time = \"all\") # 在 Google Trends 查詢「Trump」 、「Harris」和「election」(全時間、地點)，資料存成TrumpHarrisElection\nplot(TrumpHarrisElection)  #繪製TrumpHarrisElection裡儲存的資料\n\nSearching “tariff” on Google Trends\n\n# 這段程式碼會顯示，但不會執行\n\n# ---- \"tariff\" 查詢 (不限時間地點) -----\nplot(gtrends(c(\"tariff\"), time = \"all\"))  # 繪製[Google Trends 查詢「tariff｣(全時間、地點)]的資料\n\n# ---- \"tariff\" 查詢 (不限時間、特定地點) -----\ndata(\"countries\") #載入Google Trends的國家代碼\nplot(gtrends(c(\"tariff\"), geo = \"GB\", time = \"all\")) #繪製[Google Trends 查詢英國「tariff｣(全時間)]的資料\nplot(gtrends(c(\"tariff\"), geo = c(\"US\",\"GB\",\"TW\"), time = \"all\")) #繪製[Google Trends 查詢美國、英國、台灣「tariff｣(全時間)]的資料\n\n# ---- \"tariff\",\"China military\", \"Taiwan\" 查詢 (不限時間地點) -----\nplot(gtrends(c(\"tariff\",\"China military\", \"Taiwan\"), time = \"all\")) # 繪製[Google Trends 查詢「tariff」 、「China military」和「Taiwan」(全時間、地點)]的資料\n\n# ---- \"tariff\",\"China military\", \"Taiwan\" 查詢-其他代碼 -----\ntct = gtrends(c(\"tariff\",\"China military\", \"Taiwan\"), time = \"all\")  # 在Google Trends 查詢「tariff」 、「China military」和「Taiwan」(全時間、地點)]，資料存成tct\ntct = data.frame(tct$interest_over_time) # 取出tct清單中的 interest_over_time 表格；轉成 data.frame 格式，並覆蓋原本的 tct\n\n\n# ---- 補充代碼 -----\npar(family=\"Georgia\") #圖表設為Geogia字體\n\ntg = gtrends(\"tariff\", time = \"all\") # 在 Google Trends 查詢「tariff｣時間不限，資料存成tg\ntg_iot = tg$interest_over_time # 把 Google Trends 的「時間序列搜尋熱度」單獨存到tg_iot\n\ndata(\"categories\") #載入Google Trends的主題分類名稱(e.g., Health)\n\n\n\n\nSave the data into csv\n\n# 這段程式碼會顯示，但不會執行\n\n# 取出 interest_over_time (時間序列搜尋熱度)\nTrumpHarrisElection_iot &lt;- TrumpHarrisElection$interest_over_time\n\n# 存成 CSV 檔\nwrite.csv(TrumpHarrisElection_iot, \"TrumpHarrisElection.csv\", row.names = FALSE)\n\nSave the data into R formats\n\n# 這段程式碼會顯示，但不會執行\n\n# 存成 RData 格式\nsave(TrumpHarrisElection_iot, file = \"TrumpHarrisElection.RData\")\n\n# 或用 RDS (更常用)\nsaveRDS(TrumpHarrisElection_iot, \"TrumpHarrisElection.rds\")\n\nRead CSV file\n\n# 讀 CSV\nTrumpHarrisElection_csv &lt;- read.csv(\"TrumpHarrisElection.csv\")\n\nCheck time range (Dates)\n\nrange(TrumpHarrisElection_csv$date)   # 起訖時間\n\n[1] \"2004-01-01\" \"2025-09-01\"\n\n\nThe time range of the dataset is from 2004-01-01 to 2025-09-01.\nCheck intervals\n\n# 確保是時間格式\nTrumpHarrisElection_csv$date &lt;- as.POSIXct(TrumpHarrisElection_csv$date)\n\n# 只取「不同的日時」，由小到大\nuniq_dt &lt;- sort(unique(TrumpHarrisElection_csv$date))\n\n# 計算相鄰間隔（天）\ngap_days &lt;- as.numeric(diff(uniq_dt), units = \"days\")\nsummary(gap_days)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  28.00   30.00   31.00   30.44   31.00   31.04 \n\n\nThis indicates that the dataset is collected on a monthly basis, where the number of days per interval depends on the calendar month (28, 30, or 31 days).\nView each keyword trend\n\ntable(TrumpHarrisElection_csv$keyword)   # 每個關鍵字有多少筆資料\n\n\nelection   Harris    Trump \n     261      261      261 \n\n\nEach keyword (Trump, Harris, and election) has 261 observations in the dataset.\nIllustrate the comparison of three keywords\n\nlibrary(ggplot2)\n\nggplot(TrumpHarrisElection_csv, aes(x = date, y = as.numeric(hits), color = keyword)) +\n  geom_line() +\n  labs(title = \"Google Trends: Trump vs Harris vs Election\",\n       x = \"Date\", y = \"Search interest (0-100)\") +\n  theme_minimal()\n\nWarning in FUN(X[[i]], ...): NAs introduced by coercion\n\n\nWarning: Removed 3 rows containing missing values or values outside the scale range\n(`geom_line()`).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDownload data manually\nUse ‘gtrendsR’ script\n\n\n\n\nTime interval\nSelect “Past Day”; data may be hourly or every 8 minutes. Select “All Time”, data is usually monthly (YYYY-MM).\nFreely specify time = “today 1-m”, “today 12-m”, “all”, or other date ranges.\n\n\nGeography\nManually switch to a single region (e.g., Global, US).\nSet geo directly in the code as “US”, “TW”, “GB”. Compare multiple countries at once.\n\n\nData structure\nThe downloaded CSV file only has a few columns, such as “Time” and “Search Popularity for Each Keyword”.\nReturn a list containing multiple data frames:\n• $interest_over_time (time series)\n• $interest_by_region (search volume by region)\n• $related_queries (related search queries)\n• $related_topics (Related Topics)\n\n\nAdvantages\nEasy to use, ideal for quickly checking trends or making basic comparisons.\nIntegrate processes (automated analysis, archiving, plotting) in R for easy reproducibility and sharing.\n\n\nLimitations\nRequires manual operation and cannot be automatically updated or processed in batches.\nMay encounter Google Trends API rate limits (429 error). If called too frequently, may be temporarily blocked.",
    "crumbs": [
      "Home",
      "EPPS6302",
      "Assignment 2"
    ]
  },
  {
    "objectID": "DC_assignment02.html#a.-use-google-trends-website-httpstrends.google.comhome-to",
    "href": "DC_assignment02.html#a.-use-google-trends-website-httpstrends.google.comhome-to",
    "title": "Assignment 2",
    "section": "",
    "text": "Search “Trump”, “Harris”, and “election” on Google Trend website in (See bellowed plot).\n\n\n\n\n\nDownload the Google Trend data in csv file.\n\n\n\n\n\nlibrary(readxl)\nlibrary(dplyr)\nlibrary(stringr)\nlibrary(zoo)        # as.yearmon() 讓 \"YYYY-MM\" 轉成月份日期\n\n\n# 1) 讀檔：跳過前兩列的說明列\nraw &lt;- read_excel(\"TrumpHarrisElection_download.xlsx\",\n                  sheet = \"TrumpHarrisElection\", skip = 2, col_names = FALSE)\nnames(raw) &lt;- c(\"date\",\"Trump\",\"Harris\",\"election\")\n\n# 2) 清理：僅保留像 2004-01 的列，處理 \"&lt;1\"\ndf &lt;- raw %&gt;%\n  mutate(date = str_trim(as.character(date))) %&gt;%     # 去空白，確保是字串\n  filter(str_detect(date, \"^\\\\d{4}-\\\\d{2}$\")) %&gt;%     # 只留 YYYY-MM\n  mutate(\n    # 把 YYYY-MM 變成每月的第一天（Date 類型）\n    date = as.Date(as.yearmon(date)),\n    # 把 \"&lt;1\" 變 0，再轉數值\n    across(c(Trump, Harris, election), ~ as.numeric(str_replace(.x, \"&lt;1\", \"0\")))\n  ) %&gt;%\n  arrange(date)\n\n# 3) 起訖時間\nstart_date &lt;- min(df$date)\nend_date   &lt;- max(df$date)\nstart_date; end_date\n\n[1] \"2004-01-01\"\n\n\n[1] \"2025-09-01\"\n\n\nThe time range of the dataset is from 2004-01-01 to 2025-09-01.\n\n\n\n\n# 4) 時間間隔（天），確認是否為月度資料\ngap_days &lt;- diff(df$date)\nsummary(gap_days)\n\nTime differences in days\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  28.00   30.00   31.00   30.44   31.00   31.00 \n\n# 也可用「月份」為單位檢查\ngap_months &lt;- diff(as.yearmon(df$date)) * 12\nsummary(gap_months)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n      1       1       1       1       1       1 \n\n\n\nThe data are collected on a monthly basis, with most intervals being 30 or 31 days.\nThe summary shows that the minimum interval is 28 days and the maximum is 31 days, which corresponds to the varying number of days in each month.",
    "crumbs": [
      "Home",
      "EPPS6302",
      "Assignment 2"
    ]
  },
  {
    "objectID": "DC_assignment02.html#b.-use-gtrendsr-package-to-collect-data-use-gtrendsr01.r-program",
    "href": "DC_assignment02.html#b.-use-gtrendsr-package-to-collect-data-use-gtrendsr01.r-program",
    "title": "Assignment 2",
    "section": "",
    "text": "Searching “Trump”,“Harris”, & “election” on Google Trends\n\n# 這段程式碼會顯示，但不會執行\n\n#install.packages(\"gtrendsR\")\n\nlibrary(gtrendsR)\n\n# ---- \"Trump\",\"Harris\",\"election\" 查詢 (不限時間地點) -----\nTrumpHarrisElection = gtrends(c(\"Trump\",\"Harris\",\"election\"), time = \"all\") # 在 Google Trends 查詢「Trump」 、「Harris」和「election」(全時間、地點)，資料存成TrumpHarrisElection\nplot(TrumpHarrisElection)  #繪製TrumpHarrisElection裡儲存的資料\n\nSearching “tariff” on Google Trends\n\n# 這段程式碼會顯示，但不會執行\n\n# ---- \"tariff\" 查詢 (不限時間地點) -----\nplot(gtrends(c(\"tariff\"), time = \"all\"))  # 繪製[Google Trends 查詢「tariff｣(全時間、地點)]的資料\n\n# ---- \"tariff\" 查詢 (不限時間、特定地點) -----\ndata(\"countries\") #載入Google Trends的國家代碼\nplot(gtrends(c(\"tariff\"), geo = \"GB\", time = \"all\")) #繪製[Google Trends 查詢英國「tariff｣(全時間)]的資料\nplot(gtrends(c(\"tariff\"), geo = c(\"US\",\"GB\",\"TW\"), time = \"all\")) #繪製[Google Trends 查詢美國、英國、台灣「tariff｣(全時間)]的資料\n\n# ---- \"tariff\",\"China military\", \"Taiwan\" 查詢 (不限時間地點) -----\nplot(gtrends(c(\"tariff\",\"China military\", \"Taiwan\"), time = \"all\")) # 繪製[Google Trends 查詢「tariff」 、「China military」和「Taiwan」(全時間、地點)]的資料\n\n# ---- \"tariff\",\"China military\", \"Taiwan\" 查詢-其他代碼 -----\ntct = gtrends(c(\"tariff\",\"China military\", \"Taiwan\"), time = \"all\")  # 在Google Trends 查詢「tariff」 、「China military」和「Taiwan」(全時間、地點)]，資料存成tct\ntct = data.frame(tct$interest_over_time) # 取出tct清單中的 interest_over_time 表格；轉成 data.frame 格式，並覆蓋原本的 tct\n\n\n# ---- 補充代碼 -----\npar(family=\"Georgia\") #圖表設為Geogia字體\n\ntg = gtrends(\"tariff\", time = \"all\") # 在 Google Trends 查詢「tariff｣時間不限，資料存成tg\ntg_iot = tg$interest_over_time # 把 Google Trends 的「時間序列搜尋熱度」單獨存到tg_iot\n\ndata(\"categories\") #載入Google Trends的主題分類名稱(e.g., Health)",
    "crumbs": [
      "Home",
      "EPPS6302",
      "Assignment 2"
    ]
  },
  {
    "objectID": "DC_assignment02.html#c.-save-the-data-into-csv-and-r-formats.",
    "href": "DC_assignment02.html#c.-save-the-data-into-csv-and-r-formats.",
    "title": "Assignment 2",
    "section": "",
    "text": "Save the data into csv\n\n# 這段程式碼會顯示，但不會執行\n\n# 取出 interest_over_time (時間序列搜尋熱度)\nTrumpHarrisElection_iot &lt;- TrumpHarrisElection$interest_over_time\n\n# 存成 CSV 檔\nwrite.csv(TrumpHarrisElection_iot, \"TrumpHarrisElection.csv\", row.names = FALSE)\n\nSave the data into R formats\n\n# 這段程式碼會顯示，但不會執行\n\n# 存成 RData 格式\nsave(TrumpHarrisElection_iot, file = \"TrumpHarrisElection.RData\")\n\n# 或用 RDS (更常用)\nsaveRDS(TrumpHarrisElection_iot, \"TrumpHarrisElection.rds\")\n\nRead CSV file\n\n# 讀 CSV\nTrumpHarrisElection_csv &lt;- read.csv(\"TrumpHarrisElection.csv\")\n\nCheck time range (Dates)\n\nrange(TrumpHarrisElection_csv$date)   # 起訖時間\n\n[1] \"2004-01-01\" \"2025-09-01\"\n\n\nThe time range of the dataset is from 2004-01-01 to 2025-09-01.\nCheck intervals\n\n# 確保是時間格式\nTrumpHarrisElection_csv$date &lt;- as.POSIXct(TrumpHarrisElection_csv$date)\n\n# 只取「不同的日時」，由小到大\nuniq_dt &lt;- sort(unique(TrumpHarrisElection_csv$date))\n\n# 計算相鄰間隔（天）\ngap_days &lt;- as.numeric(diff(uniq_dt), units = \"days\")\nsummary(gap_days)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  28.00   30.00   31.00   30.44   31.00   31.04 \n\n\nThis indicates that the dataset is collected on a monthly basis, where the number of days per interval depends on the calendar month (28, 30, or 31 days).\nView each keyword trend\n\ntable(TrumpHarrisElection_csv$keyword)   # 每個關鍵字有多少筆資料\n\n\nelection   Harris    Trump \n     261      261      261 \n\n\nEach keyword (Trump, Harris, and election) has 261 observations in the dataset.\nIllustrate the comparison of three keywords\n\nlibrary(ggplot2)\n\nggplot(TrumpHarrisElection_csv, aes(x = date, y = as.numeric(hits), color = keyword)) +\n  geom_line() +\n  labs(title = \"Google Trends: Trump vs Harris vs Election\",\n       x = \"Date\", y = \"Search interest (0-100)\") +\n  theme_minimal()\n\nWarning in FUN(X[[i]], ...): NAs introduced by coercion\n\n\nWarning: Removed 3 rows containing missing values or values outside the scale range\n(`geom_line()`).",
    "crumbs": [
      "Home",
      "EPPS6302",
      "Assignment 2"
    ]
  },
  {
    "objectID": "DC_assignment02.html#d.-what-are-the-differences-between-the-two-methods",
    "href": "DC_assignment02.html#d.-what-are-the-differences-between-the-two-methods",
    "title": "Assignment 2",
    "section": "",
    "text": "Download data manually\nUse ‘gtrendsR’ script\n\n\n\n\nTime interval\nSelect “Past Day”; data may be hourly or every 8 minutes. Select “All Time”, data is usually monthly (YYYY-MM).\nFreely specify time = “today 1-m”, “today 12-m”, “all”, or other date ranges.\n\n\nGeography\nManually switch to a single region (e.g., Global, US).\nSet geo directly in the code as “US”, “TW”, “GB”. Compare multiple countries at once.\n\n\nData structure\nThe downloaded CSV file only has a few columns, such as “Time” and “Search Popularity for Each Keyword”.\nReturn a list containing multiple data frames:\n• $interest_over_time (time series)\n• $interest_by_region (search volume by region)\n• $related_queries (related search queries)\n• $related_topics (Related Topics)\n\n\nAdvantages\nEasy to use, ideal for quickly checking trends or making basic comparisons.\nIntegrate processes (automated analysis, archiving, plotting) in R for easy reproducibility and sharing.\n\n\nLimitations\nRequires manual operation and cannot be automatically updated or processed in batches.\nMay encounter Google Trends API rate limits (429 error). If called too frequently, may be temporarily blocked.",
    "crumbs": [
      "Home",
      "EPPS6302",
      "Assignment 2"
    ]
  },
  {
    "objectID": "DC_assignment04.html",
    "href": "DC_assignment04.html",
    "title": "Assignment 4",
    "section": "",
    "text": "Coming soon…",
    "crumbs": [
      "Home",
      "EPPS6302",
      "Assignment 4"
    ]
  },
  {
    "objectID": "DV_assignment02.html",
    "href": "DV_assignment02.html",
    "title": "Assignment 2",
    "section": "",
    "text": "Be sure to run line by line and note the changes\nPay attention to the comments and address the question if there is one\nPlotting functions (note: exercise using the happy planet data set http://happyplanetindex.org)\n\n\n\npar()\nlines()\npoints()\naxis()\nbox()\ntext()\nmtext()\nhist()\nboxplot()\nlegend()\npersp()\nnames()\npie()\n\nd. Post your works on your blog/website\n\n\n\n### Paul Murrell's R examples (selected)\n\n## Start plotting from basics \n# Note the order\nplot(pressure, pch=16)  # Can you change pch?\ntext(150, 600, \n     \"Pressure (mm Hg)\\nversus\\nTemperature (Celsius)\")\n\n\n\n\n\n\n\n#  Examples of standard high-level plots \n#  In each case, extra output is also added using low-level \n#  plotting functions.\n\n\n# Setting the parameter (3 rows by 2 cols)\npar(mfrow=c(3, 2))\n\n# Scatterplot\n# Note the incremental additions\n\nx &lt;- c(0.5, 2, 4, 8, 12, 16)\ny1 &lt;- c(1, 1.3, 1.9, 3.4, 3.9, 4.8)\ny2 &lt;- c(4, .8, .5, .45, .4, .3)\n\n# Setting label orientation, margins c(bottom, left, top, right) & text size\npar(las=1, mar=c(4, 4, 2, 4), cex=.7) \nplot.new()\nplot.window(range(x), c(0, 6))\nlines(x, y1)\nlines(x, y2)\npoints(x, y1, pch=16, cex=2) # Try different cex value?  \npoints(x, y2, pch=21, bg=\"white\", cex=2)  # Different background color\npar(col=\"gray50\", fg=\"gray50\", col.axis=\"gray50\")\naxis(1, at=seq(0, 16, 4)) # What is the first number standing for?\naxis(2, at=seq(0, 6, 2))\naxis(4, at=seq(0, 6, 2))\nbox(bty=\"u\")\nmtext(\"Travel Time (s)\", side=1, line=2, cex=0.8)\nmtext(\"Responses per Travel\", side=2, line=2, las=0, cex=0.8)\nmtext(\"Responses per Second\", side=4, line=2, las=0, cex=0.8)\ntext(4, 5, \"Bird 131\")\npar(mar=c(5.1, 4.1, 4.1, 2.1), col=\"black\", fg=\"black\", col.axis=\"black\")\n\n# Histogram\n# Random data\nY &lt;- rnorm(50)\n# Make sure no Y exceed [-3.5, 3.5]\nY[Y &lt; -3.5 | Y &gt; 3.5] &lt;- NA # Selection/set range\nx &lt;- seq(-3.5, 3.5, .1)\ndn &lt;- dnorm(x)\npar(mar=c(4.5, 4.1, 3.1, 0))\nhist(Y, breaks=seq(-3.5, 3.5), ylim=c(0, 0.5), \n     col=\"gray80\", freq=FALSE)\nlines(x, dnorm(x), lwd=2)\npar(mar=c(5.1, 4.1, 4.1, 2.1))\n\n# Barplot\npar(mar=c(2, 3.1, 2, 2.1)) \nmidpts &lt;- barplot(VADeaths, \n                  col=gray(0.1 + seq(1, 9, 2)/11), \n                  names=rep(\"\", 4))\nmtext(sub(\" \", \"\\n\", colnames(VADeaths)),\n      at=midpts, side=1, line=0.5, cex=0.5)\ntext(rep(midpts, each=5), apply(VADeaths, 2, cumsum) - VADeaths/2,\n     VADeaths, \n     col=rep(c(\"white\", \"black\"), times=3:2), \n     cex=0.8)\npar(mar=c(5.1, 4.1, 4.1, 2.1))  \n\n# Boxplot\npar(mar=c(3, 4.1, 2, 0))\nboxplot(len ~ dose, data = ToothGrowth,\n        boxwex = 0.25, at = 1:3 - 0.2,\n        subset= supp == \"VC\", col=\"white\",\n        xlab=\"\",\n        ylab=\"tooth length\", ylim=c(0,35))\nmtext(\"Vitamin C dose (mg)\", side=1, line=2.5, cex=0.8)\nboxplot(len ~ dose, data = ToothGrowth, add = TRUE,\n        boxwex = 0.25, at = 1:3 + 0.2,\n        \n        subset= supp == \"OJ\")\nlegend(1.5, 9, c(\"Ascorbic acid\", \"Orange juice\"), \n       fill = c(\"white\", \"gray\"), \n       bty=\"n\")\npar(mar=c(5.1, 4.1, 4.1, 2.1))\n\n# Persp\nx &lt;- seq(-10, 10, length= 30)\ny &lt;- x\nf &lt;- function(x,y) { r &lt;- sqrt(x^2+y^2); 10 * sin(r)/r }\nz &lt;- outer(x, y, f)\nz[is.na(z)] &lt;- 1\n# 0.5 to include z axis label\npar(mar=c(0, 0.5, 0, 0), lwd=0.5)\npersp(x, y, z, theta = 30, phi = 30, \n      expand = 0.5)\npar(mar=c(5.1, 4.1, 4.1, 2.1), lwd=1)\n\n# Piechart\npar(mar=c(0, 2, 1, 2), xpd=FALSE, cex=0.5)\npie.sales &lt;- c(0.12, 0.3, 0.26, 0.16, 0.04, 0.12)\nnames(pie.sales) &lt;- c(\"Blueberry\", \"Cherry\",\n                      \"Apple\", \"Boston Cream\", \"Other\", \"Vanilla\")\npie(pie.sales, col = gray(seq(0.3,1.0,length=6))) \n\n\n\n\n\n\n\n# Exercise: Can you generate these charts individually?  Try these functions \n# using another dataset. Be sure to work on the layout and margins\n\n\n\n\n\n# 設定工作目錄\n#setwd(\"C:/Users/dells/Desktop/quarto/quarto_website/UTD_SDAR\")\n\n# 匯入 CSV 文件\nHPIData &lt;- read.csv(\"Happy planet index.csv\")\n\n#在表格中檢視HPIdata\nView(HPIData)\n\n# Setting the parameter (3 rows by 2 cols)\npar(mfrow=c(1, 1))\n\n\n## Start plotting from basics \nplot(HPIData$GDP, HPIData$HPI, pch=16, xlab = \"GDP\", ylab = \"HPI\", main = \"Happy Planet Index (HPI) versus Gross Domestic Product (GDP)\")\ntext(100000, 55, \"HPI vs GDP\")\n\n\n\n\n\n\n\n# Scatterplot\npar(las=1, mar=c(6, 6, 4, 4), cex= .7) \nplot.new()\nplot.window(range(HPIData$GDP, na.rm = TRUE), range(HPIData$HPI, na.rm = TRUE))\nHPIData &lt;- HPIData[order(HPIData$GDP), ]\nlines(HPIData$GDP, HPIData$HPI, col=\"gray50\")\npoints(HPIData$GDP, HPIData$HPI, pch=21, bg=\"white\", cex=1) \npar(col=\"gray50\", fg=\"gray50\", col.axis=\"gray50\")\nbox(bty=\"o\")\naxis(1, at = NULL, labels = TRUE) \naxis(2, at = seq(0, 60, 10))\naxis(4, at = seq(0, 60, 10))\nmtext(\"Gross Domestic Product (GDP)\", side=1, line=3, outer=FALSE, col=\"black\", cex=0.8)\nmtext(\"Happy Planet Index (HPI)\", side=2, line=3, las=0, outer=FALSE, col=\"black\", cex=0.8)\ntext(100000, 55, \"HPI vs GDP\")\ntitle(main = \"Happy Planet Index (HPI) versus Gross Domestic Product (GDP)\")\n\n\n\n\n\n\n\npar(mar=c(5.1, 4.1, 4.1, 2.1), col=\"black\", fg=\"black\", col.axis=\"black\")\n\n\n# Histogram\npar(mar = c(4.5, 4.1, 3.1, 0))\npar(col=\"gray50\", fg=\"gray30\", col.axis=\"gray50\")\nhist(HPIData$HPI, breaks = 12, ylim = c(0, 0.06), \n     col = \"gray80\", freq = FALSE, \n     main = \"Histogram of HPI with Normal Distribution\", \n     xlab = \"Happy Planet Index (HPI)\", \n     cex.lab = 1.2) \nmean_hpi &lt;- mean(HPIData$HPI, na.rm = TRUE)\nsd_hpi &lt;- sd(HPIData$HPI, na.rm = TRUE)\nx &lt;- seq(min(HPIData$HPI, na.rm = TRUE), max(HPIData$HPI, na.rm = TRUE), length = 100)\ndn &lt;- dnorm(x, mean = mean_hpi, sd = sd_hpi)\nlines(x, dn, col = \"red\", lwd = 2)\n\n\n\n\n\n\n\npar(mar=c(5.1, 4.1, 4.1, 2.1), col=\"black\", fg=\"black\", col.axis=\"black\")\n\n# Boxplot\npar(mar=c(5, 5, 4, 2))\ncolors &lt;- c(\"lightblue\", \"lightgreen\", \"lightpink\", \"lightyellow\", \"lightgray\", \"lightcyan\", \"lavender\", \"peachpuff\")\n\nboxplot(HPI ~ Continent, data = HPIData,\n        boxwex = 0.4,\n        col = colors,\n        main = \"Happy Planet Index by Continent\",\n        ylab = \"Happy Planet Index (HPI)\",\n        xlab = \"Continent\", cex.lab = 1.2,\n        ylim=c(0,60))\ncontinent_names &lt;- c(\"Latin America\", \n                     \"North America & Oceania\", \n                     \"Western Europe\", \n                     \"Middle East & North Africa\", \n                     \"Africa\", \n                     \"South Asia\", \n                     \"Eastern Europe &  Central Asia\", \n                     \"East Asia\")\nlegend(\"bottomleft\", legend = continent_names , fill = colors)\n\n\n\n\n\n\n\n# Persp\nHPIData &lt;- HPIData[!is.na(HPIData$HPI), ]\nHPIData &lt;- HPIData[order(HPIData$HPI), ]\nx &lt;- HPIData$HPI\ny &lt;- x\nf &lt;- function(x,y) { r &lt;- sqrt(x^2+y^2); 10 * sin(r)/r }\nz &lt;- outer(x, y, f)\npar(mar=c(0, 0.5, 2.5, 0), lwd=0.9)\npersp(x, y, z, theta = 30, phi = 30, \n      expand = 0.5,\n      xlab = \"HPI\", \n      ylab = \"HPI\", \n      main = \"Perspective Plot of HPI\")\n\n\n\n\n\n\n\npar(mar=c(5.1, 4.1, 4.1, 2.1), lwd=1)\n\n\n# Piechart\ncontinent_counts &lt;- table(HPIData$Continent)\nnames(continent_counts) &lt;- c(\"Latin America\", \n                      \"North America & Oceania\", \n                      \"Western Europe\", \n                      \"Middle East & North Africa\", \n                      \"Africa\", \n                      \"South Asia\", \n                      \"Eastern Europe &  Central Asia\", \n                      \"East Asia\")\ncolors &lt;- c(\"lightblue\", \"lightgreen\", \"lightpink\", \"lightyellow\", \"lightgray\", \"lightcyan\", \"lavender\", \"peachpuff\")\npie(continent_counts, \n    labels = paste(names(continent_counts)), \n    main = \"Distribution of Continents in the Dataset\", \n    col = colors)",
    "crumbs": [
      "Home",
      "EPPS6356",
      "Assignment 2"
    ]
  },
  {
    "objectID": "DV_assignment02.html#paul-murrells-rgraphics-basic-r-programs",
    "href": "DV_assignment02.html#paul-murrells-rgraphics-basic-r-programs",
    "title": "Assignment 2",
    "section": "",
    "text": "### Paul Murrell's R examples (selected)\n\n## Start plotting from basics \n# Note the order\nplot(pressure, pch=16)  # Can you change pch?\ntext(150, 600, \n     \"Pressure (mm Hg)\\nversus\\nTemperature (Celsius)\")\n\n\n\n\n\n\n\n#  Examples of standard high-level plots \n#  In each case, extra output is also added using low-level \n#  plotting functions.\n\n\n# Setting the parameter (3 rows by 2 cols)\npar(mfrow=c(3, 2))\n\n# Scatterplot\n# Note the incremental additions\n\nx &lt;- c(0.5, 2, 4, 8, 12, 16)\ny1 &lt;- c(1, 1.3, 1.9, 3.4, 3.9, 4.8)\ny2 &lt;- c(4, .8, .5, .45, .4, .3)\n\n# Setting label orientation, margins c(bottom, left, top, right) & text size\npar(las=1, mar=c(4, 4, 2, 4), cex=.7) \nplot.new()\nplot.window(range(x), c(0, 6))\nlines(x, y1)\nlines(x, y2)\npoints(x, y1, pch=16, cex=2) # Try different cex value?  \npoints(x, y2, pch=21, bg=\"white\", cex=2)  # Different background color\npar(col=\"gray50\", fg=\"gray50\", col.axis=\"gray50\")\naxis(1, at=seq(0, 16, 4)) # What is the first number standing for?\naxis(2, at=seq(0, 6, 2))\naxis(4, at=seq(0, 6, 2))\nbox(bty=\"u\")\nmtext(\"Travel Time (s)\", side=1, line=2, cex=0.8)\nmtext(\"Responses per Travel\", side=2, line=2, las=0, cex=0.8)\nmtext(\"Responses per Second\", side=4, line=2, las=0, cex=0.8)\ntext(4, 5, \"Bird 131\")\npar(mar=c(5.1, 4.1, 4.1, 2.1), col=\"black\", fg=\"black\", col.axis=\"black\")\n\n# Histogram\n# Random data\nY &lt;- rnorm(50)\n# Make sure no Y exceed [-3.5, 3.5]\nY[Y &lt; -3.5 | Y &gt; 3.5] &lt;- NA # Selection/set range\nx &lt;- seq(-3.5, 3.5, .1)\ndn &lt;- dnorm(x)\npar(mar=c(4.5, 4.1, 3.1, 0))\nhist(Y, breaks=seq(-3.5, 3.5), ylim=c(0, 0.5), \n     col=\"gray80\", freq=FALSE)\nlines(x, dnorm(x), lwd=2)\npar(mar=c(5.1, 4.1, 4.1, 2.1))\n\n# Barplot\npar(mar=c(2, 3.1, 2, 2.1)) \nmidpts &lt;- barplot(VADeaths, \n                  col=gray(0.1 + seq(1, 9, 2)/11), \n                  names=rep(\"\", 4))\nmtext(sub(\" \", \"\\n\", colnames(VADeaths)),\n      at=midpts, side=1, line=0.5, cex=0.5)\ntext(rep(midpts, each=5), apply(VADeaths, 2, cumsum) - VADeaths/2,\n     VADeaths, \n     col=rep(c(\"white\", \"black\"), times=3:2), \n     cex=0.8)\npar(mar=c(5.1, 4.1, 4.1, 2.1))  \n\n# Boxplot\npar(mar=c(3, 4.1, 2, 0))\nboxplot(len ~ dose, data = ToothGrowth,\n        boxwex = 0.25, at = 1:3 - 0.2,\n        subset= supp == \"VC\", col=\"white\",\n        xlab=\"\",\n        ylab=\"tooth length\", ylim=c(0,35))\nmtext(\"Vitamin C dose (mg)\", side=1, line=2.5, cex=0.8)\nboxplot(len ~ dose, data = ToothGrowth, add = TRUE,\n        boxwex = 0.25, at = 1:3 + 0.2,\n        \n        subset= supp == \"OJ\")\nlegend(1.5, 9, c(\"Ascorbic acid\", \"Orange juice\"), \n       fill = c(\"white\", \"gray\"), \n       bty=\"n\")\npar(mar=c(5.1, 4.1, 4.1, 2.1))\n\n# Persp\nx &lt;- seq(-10, 10, length= 30)\ny &lt;- x\nf &lt;- function(x,y) { r &lt;- sqrt(x^2+y^2); 10 * sin(r)/r }\nz &lt;- outer(x, y, f)\nz[is.na(z)] &lt;- 1\n# 0.5 to include z axis label\npar(mar=c(0, 0.5, 0, 0), lwd=0.5)\npersp(x, y, z, theta = 30, phi = 30, \n      expand = 0.5)\npar(mar=c(5.1, 4.1, 4.1, 2.1), lwd=1)\n\n# Piechart\npar(mar=c(0, 2, 1, 2), xpd=FALSE, cex=0.5)\npie.sales &lt;- c(0.12, 0.3, 0.26, 0.16, 0.04, 0.12)\nnames(pie.sales) &lt;- c(\"Blueberry\", \"Cherry\",\n                      \"Apple\", \"Boston Cream\", \"Other\", \"Vanilla\")\npie(pie.sales, col = gray(seq(0.3,1.0,length=6))) \n\n\n\n\n\n\n\n# Exercise: Can you generate these charts individually?  Try these functions \n# using another dataset. Be sure to work on the layout and margins",
    "crumbs": [
      "Home",
      "EPPS6356",
      "Assignment 2"
    ]
  },
  {
    "objectID": "DV_assignment02.html#exercise-using-the-happy-planet-data",
    "href": "DV_assignment02.html#exercise-using-the-happy-planet-data",
    "title": "Assignment 2",
    "section": "",
    "text": "# 設定工作目錄\n#setwd(\"C:/Users/dells/Desktop/quarto/quarto_website/UTD_SDAR\")\n\n# 匯入 CSV 文件\nHPIData &lt;- read.csv(\"Happy planet index.csv\")\n\n#在表格中檢視HPIdata\nView(HPIData)\n\n# Setting the parameter (3 rows by 2 cols)\npar(mfrow=c(1, 1))\n\n\n## Start plotting from basics \nplot(HPIData$GDP, HPIData$HPI, pch=16, xlab = \"GDP\", ylab = \"HPI\", main = \"Happy Planet Index (HPI) versus Gross Domestic Product (GDP)\")\ntext(100000, 55, \"HPI vs GDP\")\n\n\n\n\n\n\n\n# Scatterplot\npar(las=1, mar=c(6, 6, 4, 4), cex= .7) \nplot.new()\nplot.window(range(HPIData$GDP, na.rm = TRUE), range(HPIData$HPI, na.rm = TRUE))\nHPIData &lt;- HPIData[order(HPIData$GDP), ]\nlines(HPIData$GDP, HPIData$HPI, col=\"gray50\")\npoints(HPIData$GDP, HPIData$HPI, pch=21, bg=\"white\", cex=1) \npar(col=\"gray50\", fg=\"gray50\", col.axis=\"gray50\")\nbox(bty=\"o\")\naxis(1, at = NULL, labels = TRUE) \naxis(2, at = seq(0, 60, 10))\naxis(4, at = seq(0, 60, 10))\nmtext(\"Gross Domestic Product (GDP)\", side=1, line=3, outer=FALSE, col=\"black\", cex=0.8)\nmtext(\"Happy Planet Index (HPI)\", side=2, line=3, las=0, outer=FALSE, col=\"black\", cex=0.8)\ntext(100000, 55, \"HPI vs GDP\")\ntitle(main = \"Happy Planet Index (HPI) versus Gross Domestic Product (GDP)\")\n\n\n\n\n\n\n\npar(mar=c(5.1, 4.1, 4.1, 2.1), col=\"black\", fg=\"black\", col.axis=\"black\")\n\n\n# Histogram\npar(mar = c(4.5, 4.1, 3.1, 0))\npar(col=\"gray50\", fg=\"gray30\", col.axis=\"gray50\")\nhist(HPIData$HPI, breaks = 12, ylim = c(0, 0.06), \n     col = \"gray80\", freq = FALSE, \n     main = \"Histogram of HPI with Normal Distribution\", \n     xlab = \"Happy Planet Index (HPI)\", \n     cex.lab = 1.2) \nmean_hpi &lt;- mean(HPIData$HPI, na.rm = TRUE)\nsd_hpi &lt;- sd(HPIData$HPI, na.rm = TRUE)\nx &lt;- seq(min(HPIData$HPI, na.rm = TRUE), max(HPIData$HPI, na.rm = TRUE), length = 100)\ndn &lt;- dnorm(x, mean = mean_hpi, sd = sd_hpi)\nlines(x, dn, col = \"red\", lwd = 2)\n\n\n\n\n\n\n\npar(mar=c(5.1, 4.1, 4.1, 2.1), col=\"black\", fg=\"black\", col.axis=\"black\")\n\n# Boxplot\npar(mar=c(5, 5, 4, 2))\ncolors &lt;- c(\"lightblue\", \"lightgreen\", \"lightpink\", \"lightyellow\", \"lightgray\", \"lightcyan\", \"lavender\", \"peachpuff\")\n\nboxplot(HPI ~ Continent, data = HPIData,\n        boxwex = 0.4,\n        col = colors,\n        main = \"Happy Planet Index by Continent\",\n        ylab = \"Happy Planet Index (HPI)\",\n        xlab = \"Continent\", cex.lab = 1.2,\n        ylim=c(0,60))\ncontinent_names &lt;- c(\"Latin America\", \n                     \"North America & Oceania\", \n                     \"Western Europe\", \n                     \"Middle East & North Africa\", \n                     \"Africa\", \n                     \"South Asia\", \n                     \"Eastern Europe &  Central Asia\", \n                     \"East Asia\")\nlegend(\"bottomleft\", legend = continent_names , fill = colors)\n\n\n\n\n\n\n\n# Persp\nHPIData &lt;- HPIData[!is.na(HPIData$HPI), ]\nHPIData &lt;- HPIData[order(HPIData$HPI), ]\nx &lt;- HPIData$HPI\ny &lt;- x\nf &lt;- function(x,y) { r &lt;- sqrt(x^2+y^2); 10 * sin(r)/r }\nz &lt;- outer(x, y, f)\npar(mar=c(0, 0.5, 2.5, 0), lwd=0.9)\npersp(x, y, z, theta = 30, phi = 30, \n      expand = 0.5,\n      xlab = \"HPI\", \n      ylab = \"HPI\", \n      main = \"Perspective Plot of HPI\")\n\n\n\n\n\n\n\npar(mar=c(5.1, 4.1, 4.1, 2.1), lwd=1)\n\n\n# Piechart\ncontinent_counts &lt;- table(HPIData$Continent)\nnames(continent_counts) &lt;- c(\"Latin America\", \n                      \"North America & Oceania\", \n                      \"Western Europe\", \n                      \"Middle East & North Africa\", \n                      \"Africa\", \n                      \"South Asia\", \n                      \"Eastern Europe &  Central Asia\", \n                      \"East Asia\")\ncolors &lt;- c(\"lightblue\", \"lightgreen\", \"lightpink\", \"lightyellow\", \"lightgray\", \"lightcyan\", \"lavender\", \"peachpuff\")\npie(continent_counts, \n    labels = paste(names(continent_counts)), \n    main = \"Distribution of Continents in the Dataset\", \n    col = colors)",
    "crumbs": [
      "Home",
      "EPPS6356",
      "Assignment 2"
    ]
  },
  {
    "objectID": "DV_assignment04.html",
    "href": "DV_assignment04.html",
    "title": "Assignment 4",
    "section": "",
    "text": "knitr::opts_chunk$set(warning = FALSE)",
    "crumbs": [
      "Home",
      "EPPS6356",
      "Assignment 4"
    ]
  },
  {
    "objectID": "DV_assignment04.html#chart-1-by-mamie-cincotta",
    "href": "DV_assignment04.html#chart-1-by-mamie-cincotta",
    "title": "Assignment 4",
    "section": "Chart 1 by Mamie Cincotta",
    "text": "Chart 1 by Mamie Cincotta\nThis graphic is a bar plot depicting the carbon footprint of different regions around the world, with each bar’s width proportional to the population size of the corresponding region. The y-axis represents the total carbon footprint in metric tons of CO₂ equivalent (tCO₂e) for each region, while the x-axis lists the regions, including South America, North America & Oceania, Western Europe, and others. The names of the regions are displayed at an angle for readability (due to las = 2), and the bar widths are scaled based on the population size for each region, emphasizing the relative population contribution to the region’s carbon footprint. The color of the bars is set to “steelblue,” and the overall title of the plot is “Carbon Footprint by Region with Population Widths,” illustrating the relationship between population and carbon emissions across different global regions.\n\n# Aggregate data\ncontems &lt;- aggregate(happyplanetdf$\"Carbon Footprint (tCO2e)\", list(happyplanetdf$Continent), FUN = sum)\ncontpop &lt;- aggregate(happyplanetdf$\"Population (thousands)\", list(happyplanetdf$Continent), FUN = sum)\n \n# Name the regions\nnames &lt;- c(\"South America\", \"North America and Oceania\",\"Western Europe\",\"Middle East\", \"Africa\", \"South Asia\", \"Eastern Europe & Central Asia\", \"East Asia\")\ndata &lt;- data.frame(contems, names)\n \n# Make the plot\nbarplot(width = contpop$x, height = contems$x, names=rep(data$names), las = 2, cex.names=.5, ylab = \"Carbon Footprint\", xlab = \"Region\", main = \"Carbon Footprint by Region with Population Widths\", col = \"steelblue\")",
    "crumbs": [
      "Home",
      "EPPS6356",
      "Assignment 4"
    ]
  },
  {
    "objectID": "DV_assignment04.html#chart-2-by-warren-cox",
    "href": "DV_assignment04.html#chart-2-by-warren-cox",
    "title": "Assignment 4",
    "section": "Chart 2 by Warren Cox",
    "text": "Chart 2 by Warren Cox\nThis code generates a scatterplot matrix for key variables in the Happy Planet Index (HPI) dataset, providing a visual representation of the relationships between six different variables: Population, Life Expectancy, Wellbeing (Ladder of Life), Carbon Footprint, HPI, and GDP per capita. The matrix includes pairwise scatterplots that help identify potential correlations between variables.\nThis matrix helps identify potential trends, correlations, and distributions in the HPI data. It can reveal patterns such as whether regions with higher GDP per capita also have higher well-being or lower carbon footprints, and allows users to explore multivariate relationships between the key HPI indicators.\n\nselected_data &lt;- happyplanetdf[c(\"Population (thousands)\",\"Life Expectancy (years)\",\"Ladder of life (Wellbeing) (0-10)\",\"Carbon Footprint (tCO2e)\",\"HPI\",\"GDP per capita ($)\", \"Continent\")]\n \npar(family = \"serif\", cex = 1.5) \nlibrary(psych)\npairs.panels(selected_data[1:6],\n             main = \"Scatterplot Matrix of HPI Data Variables\",\n             method = \"pearson\", # correlation method\n             hist.col = \"forestgreen\",\n             density = TRUE,  # show density plots\n             ellipses = FALSE)",
    "crumbs": [
      "Home",
      "EPPS6356",
      "Assignment 4"
    ]
  },
  {
    "objectID": "DV_assignment04.html#chart-3-by-liberty-smith",
    "href": "DV_assignment04.html#chart-3-by-liberty-smith",
    "title": "Assignment 4",
    "section": "Chart 3 by Liberty Smith",
    "text": "Chart 3 by Liberty Smith\nThis horizontal stacked bar chart visualizes the distribution of countries by Wellbeing Category across various continents. The x-axis represents the number of countries in each continent, while the y-axis lists the continents, including Latin America, North America & Oceania, Western Europe, and others. Each bar is stacked by Wellbeing Category (Good, Average, Poor), with different colors indicating the categories: seagreen for “Good,” goldenrod for “Average,” and firebrick for “Poor.” The chart allows for easy comparison of how countries within each continent are distributed across these wellbeing categories, with the custom labels improving readability. The use of coord_flip() makes the bars horizontal, providing a clear and concise visual representation of the data.\n\nlibrary(ggplot2)\n\n\nAttaching package: 'ggplot2'\n\n\nThe following objects are masked from 'package:psych':\n\n    %+%, alpha\n\nlibrary(tidyr)\n\n# Categorize Life Expectancy, Wellbeing, and Carbon Footprint\nhappyplanetdf &lt;- happyplanetdf %&gt;%\n  \n  # Categorize Wellbeing\n  mutate(Wellbeing_Category = case_when(\n    `Ladder of life (Wellbeing) (0-10)` &lt; 5.0 ~ \"Poor\",\n    `Ladder of life (Wellbeing) (0-10)` &gt;= 5.1 & `Ladder of life (Wellbeing) (0-10)` &lt; 6.0 ~ \"Average\",\n    `Ladder of life (Wellbeing) (0-10)` &gt;= 6.0 ~ \"Good\",\n    TRUE ~ NA_character_  # For missing values, set NA\n  ))\n# Remove NA values in Wellbeing_Category for this plot\nclean_data &lt;- happyplanetdf %&gt;%\n  filter(!is.na(Wellbeing_Category))\n\n# Count the number of countries per continent and wellbeing category\ncount_data &lt;- clean_data %&gt;%\n  group_by(Continent, Wellbeing_Category) %&gt;%\n  summarise(Count = n()) %&gt;%\n  ungroup()\n\n`summarise()` has grouped output by 'Continent'. You can override using the\n`.groups` argument.\n\n# Custom continent labels\ncontinent_labels &lt;- c(\n  \"1\" = \"Latin\\nAmerica\",\n  \"2\" = \"N. America\\n& Oceania\",\n  \"3\" = \"Western\\nEurope\",\n  \"4\" = \"Middle\\nEast\",\n  \"5\" = \"Africa\",\n  \"6\" = \"South\\nAsia\",\n  \"7\" = \"Eastern Europe\\n& Central Asia\",\n  \"8\" = \"East\\nAsia\"\n)\n\n# Create the horizontal stacked bar chart\nggplot(count_data, aes(x = Continent, y = Count, fill = Wellbeing_Category)) +\n  geom_bar(stat = \"identity\") +\n  scale_x_discrete(labels = continent_labels) +  # Apply custom labels\n  labs(title = \"Number of Countries per Continent by Wellbeing Category\",\n       x = \"Continent\", y = \"Number of Countries\", fill = \"Wellbeing Category\") +\n  scale_fill_manual(values = c(\"Good\" = \"seagreen\", \"Average\" = \"goldenrod\", \"Poor\" = \"firebrick\")) +\n  theme_minimal() +\n  coord_flip()  # This flips the chart horizontally",
    "crumbs": [
      "Home",
      "EPPS6356",
      "Assignment 4"
    ]
  },
  {
    "objectID": "DV_assignment04.html#chart-4-by-shiu-ting-ling",
    "href": "DV_assignment04.html#chart-4-by-shiu-ting-ling",
    "title": "Assignment 4",
    "section": "Chart 4 By Shiu-Ting Ling",
    "text": "Chart 4 By Shiu-Ting Ling\nThis bar chart depicts the number of countries in each continent that have an HPI (Happy Planet Index) above or below the global average. The x-axis represents continents, with custom labels such as “Latin America,” “Western Europe,” and “East Asia.” The y-axis represents the number of countries in each continent. The chart differentiates between countries with higher HPI (colored in firebrick2) and those with lower HPI (colored in dodgerblue2), using side-by-side bars for each continent to indicate the count. The custom labels in the legend clarify the categories: “Countries with higher HPI” and “Countries with lower HPI.” The chart’s title, “Number of Countries Above/Below Average HPI by Continent,” succinctly summarizes the data. The labels on the x-axis are kept horizontal for readability, and the minimalist theme ensures the focus remains on the data while small adjustments like legend size and text formatting improve the overall presentation.\n\n# Calculate the average HPI for all countries\naverage_hpi &lt;- mean(happyplanetdf$HPI, na.rm = TRUE)\n\n# Define custom continent names\ncontinent_names &lt;- c(\"Africa\", \n                     \"Latin\\nAmerica\", \n                     \"North\\nAmerica\\n&\\nOceania\", \n                     \"Eastern\\nEurope\\n&\\nCentral\\nAsia\", \n                     \"East\\nAsia\", \n                     \"Middle\\nEast\\n&\\nNorth\\nAfrica\", \n                     \"South\\nAsia\", \n                     \"Western\\nEurope\")\n\n# Update the Continent column as a factor and assign custom labels\nhappyplanetdf$Continent &lt;- factor(happyplanetdf$Continent, \n                                  levels = 1:8, \n                                  labels = continent_names)\n\n# Calculate the number of countries in each continent above and below the average HPI\ncontinent_hpi_comparison &lt;- happyplanetdf %&gt;%\n    group_by(Continent) %&gt;%\n    summarise(\n        High_HPI_Count = sum(HPI &gt; average_hpi, na.rm = TRUE),\n        Low_HPI_Count = sum(HPI &lt;= average_hpi, na.rm = TRUE)\n    ) %&gt;%\n    pivot_longer(cols = c(\"High_HPI_Count\", \"Low_HPI_Count\"), names_to = \"HPI_Category\", values_to = \"Country_Count\")\n\n# Use ggplot2 to create a bar chart and adjust the angle of x-axis labels\nggplot(continent_hpi_comparison, aes(x = Continent, y = Country_Count, fill = HPI_Category)) +\n    geom_bar(stat = \"identity\", position = \"dodge\") +\n    labs(title = \"Number of Countries Above/Below Average HPI by Continent\",\n         x = \"Continent\",\n         y = \"Number of Countries\",\n         fill = \"HPI Category\") +\n    scale_fill_manual(\n        values = c(\"High_HPI_Count\" = \"firebrick2\", \"Low_HPI_Count\" = \"dodgerblue2\"),  # Optional: Define custom colors for each category\n        labels = c(\"High_HPI_Count\" = \"Countries with\\nhigher HPI\", \n                   \"Low_HPI_Count\" = \"Countries with\\nlower HPI\")  # Change legend labels\n    ) +\n    theme_minimal() +\n    theme(\n        legend.position = \"right\",                  # Set legend position to the right\n        legend.key.size = unit(0.5, \"cm\"),           # Make the legend boxes smaller\n        legend.text = element_text(size = 6),        # Change the legend text size\n        axis.text.x = element_text(size = 8,         # Adjust x-axis label text size\n                                   angle = 0,        # Keep x-axis labels horizontal\n                                   hjust = 0.5,        # Adjust horizontal alignment\n                                   vjust = 0.5,),      # Adjust vertical alignment\n        plot.title = element_text(size = 12,         # Increase the title font size\n                                  face = \"bold\",     # Set title to bold\n                                  margin = margin(t = 10, b = 10))  # Add margin to title for spacing\n    )",
    "crumbs": [
      "Home",
      "EPPS6356",
      "Assignment 4"
    ]
  },
  {
    "objectID": "DV_assignment06.html",
    "href": "DV_assignment06.html",
    "title": "Assignment 6",
    "section": "",
    "text": "Can you change to your personal font?\nHint: Append the following to the ui part of the program tags$style(HTML(” body { background-color: white; color: black; } h1 { font-family: ‘Palatino’, sans-serif; } .shiny-input-container { color: #000000; }“))",
    "crumbs": [
      "Home",
      "EPPS6356",
      "Assignment 6"
    ]
  },
  {
    "objectID": "DV_assignment06.html#example",
    "href": "DV_assignment06.html#example",
    "title": "Assignment 6",
    "section": "Example:",
    "text": "Example:",
    "crumbs": [
      "Home",
      "EPPS6356",
      "Assignment 6"
    ]
  },
  {
    "objectID": "DV_assignment06.html#my-shiny-app",
    "href": "DV_assignment06.html#my-shiny-app",
    "title": "Assignment 6",
    "section": "My shiny app:",
    "text": "My shiny app:",
    "crumbs": [
      "Home",
      "EPPS6356",
      "Assignment 6"
    ]
  },
  {
    "objectID": "DV_assignment08.html",
    "href": "DV_assignment08.html",
    "title": "Assignment 8",
    "section": "",
    "text": "See #4",
    "crumbs": [
      "Home",
      "EPPS6356",
      "Assignment 8"
    ]
  },
  {
    "objectID": "DV_assignment08.html#texas-voter-turnout-rate-data",
    "href": "DV_assignment08.html#texas-voter-turnout-rate-data",
    "title": "Assignment 8",
    "section": "Texas Voter Turnout Rate Data",
    "text": "Texas Voter Turnout Rate Data\n\n\nSource: Texas Voter Turnout Rate Data",
    "crumbs": [
      "Home",
      "EPPS6356",
      "Assignment 8"
    ]
  },
  {
    "objectID": "IM_assignment02.html",
    "href": "IM_assignment02.html",
    "title": "Assignment 2",
    "section": "",
    "text": "Answer all questions. Prepare your answers in presentation format and be ready to present in class\n\n1. What are the differences between relation schema, relation and instance? Give an example using the university database to illustrate.\n1. Relation: the table.\n\n2. Relation schema: the logical design of the relation, consisting of a list of attributes and their corresponding domains. The schema of a relation typically does not change.\nInstrctor (ID, Name, depart_name, salary)\n3. Relation instance: a snapshot of data in the relation at a specific point in time. It corresponds to the programming language concept of a variable’s value. The value of a variable may change over time; similarly, the contents of a relation instance may change over time as the relation is updated.\nAssume that in the first week of the 2025 Spring semester, the instance of the instructor and department table is as follows:\n\nIf data is later added or deleted, the instance will change.\n\n\n2. Draw a schema diagram for the following bank database:\n\n\n\n\n3. Consider the above bank database. Assume that branch names (branch_name)and customer names (customer_name)uniquely identify branches and customers, but loans and accounts can be associated with more than one customer.\n\nWhat are the appropriate primary keys? (Underline each in diagram)\nGiven your choice of primary keys, identify appropriate foreign keys.\n\nSchema diagram was seen in # 2\n\nrepresents primary key.\n\nrepresents foreign key.\nSummary:\n1. Primary keys\n\nbranch：branch_name\ncustomer：ID\nloan：loan_number\nborrower：ID, loan_number\naccount：account_number\ndepositor：ID, account_number\n\n2. Foreign keys\n\nloan.branch_name → branch.branch_name\nborrower.ID → customer.ID\nborrower.loan_number → loan.loan_number\naccount.branch_name → branch.branch_name\ndepositor.ID → customer.ID\ndepositor.account_number → account.account_number",
    "crumbs": [
      "Home",
      "EPPS6354",
      "Assignment 2"
    ]
  },
  {
    "objectID": "IM_assignment04.html",
    "href": "IM_assignment04.html",
    "title": "Assignment 4",
    "section": "",
    "text": "Answer 1, 2 and two in 3 (i.e. 3a, 3b | 3b, 3c |3a, 3c). Prepare your answers in presentation format and be ready to present in class",
    "crumbs": [
      "Home",
      "EPPS6354",
      "Assignment 4"
    ]
  },
  {
    "objectID": "IM_assignment04.html#a-draw-the-e-r-diagram-using-draw.io.-read-this-website-for-instructions.",
    "href": "IM_assignment04.html#a-draw-the-e-r-diagram-using-draw.io.-read-this-website-for-instructions.",
    "title": "Assignment 4",
    "section": "(a) Draw the E-R diagram using draw.io. Read this website for instructions.",
    "text": "(a) Draw the E-R diagram using draw.io. Read this website for instructions.",
    "crumbs": [
      "Home",
      "EPPS6354",
      "Assignment 4"
    ]
  },
  {
    "objectID": "IM_assignment04.html#b-expand-to-all-teams-in-the-league-hint-add-team-entity",
    "href": "IM_assignment04.html#b-expand-to-all-teams-in-the-league-hint-add-team-entity",
    "title": "Assignment 4",
    "section": "(b) Expand to all teams in the league (Hint: add team entity)",
    "text": "(b) Expand to all teams in the league (Hint: add team entity)",
    "crumbs": [
      "Home",
      "EPPS6354",
      "Assignment 4"
    ]
  },
  {
    "objectID": "IM_assignment04.html#a-consider-the-query",
    "href": "IM_assignment04.html#a-consider-the-query",
    "title": "Assignment 4",
    "section": "(a) Consider the query",
    "text": "(a) Consider the query\n\n\nfile.exists(\"sql.db\")\n\n[1] TRUE\n\nlibrary(DBI)\nlibrary(RSQLite)\n\n# Establishing a SQLite Connection\nconn &lt;- dbConnect(SQLite(), \"sql.db\")\n\n# Set Quarto to use this SQL connection\nknitr::opts_chunk$set(connection = conn)\n\n\nselect course_id, semester, year, sec_id, avg (tot_cred)  \nfrom takes natural join student  \nwhere year = 2017  \ngroup by course_id, semester, year, sec_id  \nhaving count (ID) &gt;= 2;\n\n\n3 records\n\n\ncourse_id\nsemester\nyear\nsec_id\navg (tot_cred)\n\n\n\n\nCS-101\nFall\n2017\n1\n65\n\n\nCS-190\nSpring\n2017\n2\n43\n\n\nCS-347\nFall\n2017\n1\n67\n\n\n\n\n\n\ni Explain why appending natural join section in the from clause would not change the result. (Consult Ch. 4, 4.1.1)\nAdding NATURAL JOIN section does not change the result because the takes table already contains the necessary attributes (course_id, semester, year, sec_id) that are also present in section. The natural join would not introduce any new information but merely duplicate existing data. As a result, the GROUP BY and HAVING conditions remain unaffected, and the query’s output stays the same.\n\n\nii Test the results using the Online SQL interpreter (https://www.dbbook.com/university-lab-dir/sqljs.html)\n\nselect course_id, semester, year, sec_id, avg (tot_cred)  \nfrom takes natural join student natural join section  \nwhere year = 2017  \ngroup by course_id, semester, year, sec_id  \nhaving count (ID) &gt;= 2;\n\n\n3 records\n\n\ncourse_id\nsemester\nyear\nsec_id\navg (tot_cred)\n\n\n\n\nCS-101\nFall\n2017\n1\n65\n\n\nCS-190\nSpring\n2017\n2\n43\n\n\nCS-347\nFall\n2017\n1\n67",
    "crumbs": [
      "Home",
      "EPPS6354",
      "Assignment 4"
    ]
  },
  {
    "objectID": "IM_assignment04.html#b-write-an-sql-query-using-the-university-schema-to-find-the-id-of-each-student-who-has-never-taken-a-course-at-the-university.-do-this-using-no-subqueries-and-no-set-operations-use-an-outer-join.-consult-ch.-4-4.1.3",
    "href": "IM_assignment04.html#b-write-an-sql-query-using-the-university-schema-to-find-the-id-of-each-student-who-has-never-taken-a-course-at-the-university.-do-this-using-no-subqueries-and-no-set-operations-use-an-outer-join.-consult-ch.-4-4.1.3",
    "title": "Assignment 4",
    "section": "(b) Write an SQL query using the university schema to find the ID of each student who has never taken a course at the university. Do this using no subqueries and no set operations (use an outer join). (Consult Ch. 4, 4.1.3)",
    "text": "(b) Write an SQL query using the university schema to find the ID of each student who has never taken a course at the university. Do this using no subqueries and no set operations (use an outer join). (Consult Ch. 4, 4.1.3)\n\nSELECT student.ID  \nFROM student  \nLEFT OUTER JOIN takes ON student.ID = takes.ID  \nWHERE takes.ID IS NULL;\n\n\n1 records\n\n\nID\n\n\n\n\n70557",
    "crumbs": [
      "Home",
      "EPPS6354",
      "Assignment 4"
    ]
  },
  {
    "objectID": "IM_assignment04.html#c-consider-the-following-database-write-a-query-to-find-the-id-of-each-employee-with-no-manager.-note-that-an-employee-may-simply-have-no-manager-listed-or-may-have-a-null-manageruse-natural-left-outer-join.-consult-ch.-4-4.1.3",
    "href": "IM_assignment04.html#c-consider-the-following-database-write-a-query-to-find-the-id-of-each-employee-with-no-manager.-note-that-an-employee-may-simply-have-no-manager-listed-or-may-have-a-null-manageruse-natural-left-outer-join.-consult-ch.-4-4.1.3",
    "title": "Assignment 4",
    "section": "(c) Consider the following database, write a query to find the ID of each employee with no manager. Note that an employee may simply have no manager listed or may have a null manager(use natural left outer join). (Consult Ch. 4, 4.1.3)",
    "text": "(c) Consider the following database, write a query to find the ID of each employee with no manager. Note that an employee may simply have no manager listed or may have a null manager(use natural left outer join). (Consult Ch. 4, 4.1.3)\n\nSELECT employee.ID  \nFROM employee  \nNATURAL LEFT OUTER JOIN manages  \nWHERE manages.manager_id IS NULL;",
    "crumbs": [
      "Home",
      "EPPS6354",
      "Assignment 4"
    ]
  },
  {
    "objectID": "IM_assignment06.html",
    "href": "IM_assignment06.html",
    "title": "Assignment 6",
    "section": "",
    "text": "Answer all of the following: Prepare your answers in presentation format and be ready to present in class",
    "crumbs": [
      "Home",
      "EPPS6354",
      "Assignment 6"
    ]
  },
  {
    "objectID": "IM_assignment06.html#i-express-the-following-query-in-sql-using-no-subqueries-and-no-set-operations.-hint-left-outer-join",
    "href": "IM_assignment06.html#i-express-the-following-query-in-sql-using-no-subqueries-and-no-set-operations.-hint-left-outer-join",
    "title": "Assignment 6",
    "section": "i Express the following query in SQL using no subqueries and no set operations. (Hint: left outer join)",
    "text": "i Express the following query in SQL using no subqueries and no set operations. (Hint: left outer join)\n\n\nfile.exists(\"sql.db\")\n\n[1] TRUE\n\nlibrary(DBI)\nlibrary(RSQLite)\n\n# Establishing a SQLite Connection\nconn &lt;- dbConnect(SQLite(), \"sql.db\")\n\n# Set Quarto to use this SQL connection\nknitr::opts_chunk$set(connection = conn)\n\n\nselect ID\nfrom student\nexcept\nselect s_id\nfrom advisor\nwhere i_ID is not null\n\n\n4 records\n\n\nID\n\n\n\n\n19991\n\n\n54321\n\n\n55739\n\n\n70557\n\n\n\n\n\nThe result shows the student IDs that appear in the student table but not in the advisor table (i.e., the students who do not have an advisor).\nThen, rewrite using LEFT OUTER JOIN.\n\nselect s.ID\nfrom student s\nleft join advisor a on s.ID = a.s_id\nwhere a.s_id is null;\n\n\n4 records\n\n\nID\n\n\n\n\n19991\n\n\n54321\n\n\n55739\n\n\n70557",
    "crumbs": [
      "Home",
      "EPPS6354",
      "Assignment 6"
    ]
  },
  {
    "objectID": "IM_assignment06.html#ii-using-the-university-schema-write-an-sql-query-to-find-the-names-and-ids-of-those-instructors-who-teach-every-course-taught-in-his-or-her-department-i.e.-every-course-that-appears-in-the-course-relation-with-the-instructors-department-name.-order-result-by-name.",
    "href": "IM_assignment06.html#ii-using-the-university-schema-write-an-sql-query-to-find-the-names-and-ids-of-those-instructors-who-teach-every-course-taught-in-his-or-her-department-i.e.-every-course-that-appears-in-the-course-relation-with-the-instructors-department-name.-order-result-by-name.",
    "title": "Assignment 6",
    "section": "ii Using the university schema, write an SQL query to find the names and IDs of those instructors who teach every course taught in his or her department (i.e., every course that appears in the course relation with the instructor’s department name). Order result by name.",
    "text": "ii Using the university schema, write an SQL query to find the names and IDs of those instructors who teach every course taught in his or her department (i.e., every course that appears in the course relation with the instructor’s department name). Order result by name.\n\nselect i.ID, i.name\nfrom instructor i\nwhere not exists (\n  select c.course_id\n  from course c\n  where c.dept_name = i.dept_name\n    and not exists (\n      select t.course_id\n      from teaches t\n      where t.ID = i.ID and t.course_id = c.course_id\n    )\n)\norder by i.name;\n\n\n5 records\n\n\nID\nname\n\n\n\n\n22222\nEinstein\n\n\n32343\nEl Said\n\n\n98345\nKim\n\n\n15151\nMozart\n\n\n12121\nWu",
    "crumbs": [
      "Home",
      "EPPS6354",
      "Assignment 6"
    ]
  },
  {
    "objectID": "IM_assignment06.html#a-import-the-full-database-using-sql-code-for-creating-large-relations-from-textbook-website",
    "href": "IM_assignment06.html#a-import-the-full-database-using-sql-code-for-creating-large-relations-from-textbook-website",
    "title": "Assignment 6",
    "section": "(a) Import the full database using SQL code for creating large relations (from textbook website)",
    "text": "(a) Import the full database using SQL code for creating large relations (from textbook website)",
    "crumbs": [
      "Home",
      "EPPS6354",
      "Assignment 6"
    ]
  },
  {
    "objectID": "IM_assignment06.html#b-run-rpostgres01.r-in-teams-r-folder",
    "href": "IM_assignment06.html#b-run-rpostgres01.r-in-teams-r-folder",
    "title": "Assignment 6",
    "section": "(b) Run RPostgres01.R (in Teams R folder)",
    "text": "(b) Run RPostgres01.R (in Teams R folder)",
    "crumbs": [
      "Home",
      "EPPS6354",
      "Assignment 6"
    ]
  },
  {
    "objectID": "IM_assignment06.html#c-post-results-on-website",
    "href": "IM_assignment06.html#c-post-results-on-website",
    "title": "Assignment 6",
    "section": "(c) Post results on website",
    "text": "(c) Post results on website\n\n# Check required packages\nrequired_packages &lt;- c(\"RPostgres\", \"DBI\", \"odbc\")\nmissing &lt;- setdiff(required_packages, rownames(installed.packages()))\nif (length(missing) &gt; 0) {\n  knitr::opts_chunk$set(eval = FALSE)\n  stop(\"Missing packages: \", paste(missing, collapse = \", \"), \n       \". Please install them manually in the R console.\")\n}\n\n# Optional: cleaner tables (no NA shown)\noptions(knitr.kable.NA = '')\n\n# Load libraries\nlibrary(RPostgres)\nlibrary(DBI)\nlibrary(odbc)\n\n# Connect to PostgreSQL\ncon &lt;- dbConnect(\n  RPostgres::Postgres(),\n  dbname   = \"university\",\n  host     = \"localhost\",\n  port     = 5432,\n  user     = \"postgres\",\n  password = \"Ting87724$\"\n)\n\n# Perform queries\ninstructor_data &lt;- dbGetQuery(con, \"SELECT * FROM instructor\")\ncomp_sci_instructors &lt;- dbGetQuery(\n  con, \n  \"SELECT * FROM instructor \n   WHERE dept_name = 'Comp. Sci.' AND salary &gt; 60000;\"\n)\nstudent_data &lt;- dbGetQuery(con, \"SELECT * FROM student WHERE tot_cred &gt;= 50\")\n\n# Show results in HTML using kable (with English captions)\nknitr::kable(head(instructor_data, 10), caption = \"Top 10 Instructor Records\")\n\n\nTop 10 Instructor Records\n\n\nid\nname\ndept_name\nsalary\n\n\n\n\n63395\nMcKinnon\nCybernetics\n94333.99\n\n\n78699\nPingr\nStatistics\n59303.62\n\n\n96895\nMird\nMarketing\n119921.41\n\n\n4233\nLuo\nEnglish\n88791.45\n\n\n4034\nMurata\nAthletics\n61387.56\n\n\n50885\nKonstantinides\nLanguages\n32570.50\n\n\n79653\nLevine\nElec. Eng.\n89805.83\n\n\n50330\nShuming\nPhysics\n108011.81\n\n\n80759\nQueiroz\nBiology\n45538.32\n\n\n73623\nSullivan\nElec. Eng.\n90038.09\n\n\n\n\nknitr::kable(comp_sci_instructors, caption = \"Computer Science Instructors with Salary &gt; 60000\")\n\n\nComputer Science Instructors with Salary &gt; 60000\n\n\nid\nname\ndept_name\nsalary\n\n\n\n\n34175\nBondi\nComp. Sci.\n115469.11\n\n\n3335\nBourrier\nComp. Sci.\n80797.83\n\n\n\n\nknitr::kable(head(student_data), caption = \"Students with Total Credits &gt;= 50\")\n\n\nStudents with Total Credits &gt;= 50\n\n\nid\nname\ndept_name\ntot_cred\n\n\n\n\n79352\nRumat\nFinance\n100\n\n\n76672\nMiliko\nStatistics\n116\n\n\n14182\nMoszkowski\nCivil Eng.\n73\n\n\n44985\nPrieto\nBiology\n91\n\n\n44271\nSowerby\nEnglish\n108\n\n\n40897\nCoppens\nMath\n58\n\n\n\n\n# Disconnect\ndbDisconnect(con)\n\n```",
    "crumbs": [
      "Home",
      "EPPS6354",
      "Assignment 6"
    ]
  },
  {
    "objectID": "IM_Final.html",
    "href": "IM_Final.html",
    "title": "Traditional Chinese Medicine for Everyday Wellness - A Searchable Health Preservation Database",
    "section": "",
    "text": "Schema in E-R Model",
    "crumbs": [
      "Home",
      "EPPS6354",
      "Final Presentation"
    ]
  },
  {
    "objectID": "IM_Final.html#tcm-shinyapp-english-version",
    "href": "IM_Final.html#tcm-shinyapp-english-version",
    "title": "Traditional Chinese Medicine for Everyday Wellness - A Searchable Health Preservation Database",
    "section": "2.1 TCM Shinyapp (English version)",
    "text": "2.1 TCM Shinyapp (English version)\n\n\nSource: Integrated TCM Query System",
    "crumbs": [
      "Home",
      "EPPS6354",
      "Final Presentation"
    ]
  },
  {
    "objectID": "IM_Final.html#tcm-shinyapp-chinese-version",
    "href": "IM_Final.html#tcm-shinyapp-chinese-version",
    "title": "Traditional Chinese Medicine for Everyday Wellness - A Searchable Health Preservation Database",
    "section": "2.2 TCM Shinyapp (Chinese version)",
    "text": "2.2 TCM Shinyapp (Chinese version)\n\n\nSource: 中醫整合查詢系統",
    "crumbs": [
      "Home",
      "EPPS6354",
      "Final Presentation"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome!",
    "section": "",
    "text": "This is Ling’s learning journal at UTD. 📚📝"
  }
]